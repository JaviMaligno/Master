	\documentclass[twoside]{article}
\usepackage{../../estilo-ejercicios}
%\renewcommand{\baselinestretch}{1,3}
%--------------------------------------------------------
\begin{document}

\title{Ejercicios de Teoría de Representaciones}
\author{Javier Aguilar Martín y Rafael González López}
\maketitle

\section{Ejercicio del profesor}
\begin{ejercicio}{1}
Demostrar que si $A$ es conmutativa y $k$ es algebraicamente cerrado, todas las representaciones irreducibles de dimensión finita de $A$ son de dimensión 1. 
\end{ejercicio}
\begin{solucion}
Sea $V$ una representación irreducible cualquiera de $A$. Para $a,b\in A$ cualquiesquiera, tenemos $ab=ba$, luego para todo $v\in V$ tenemos $a(bv) =ab(v)=ba(v)=b(av)$
\[
\begin{tikzcd}
V\arrow[r, "b"] \arrow[d, "a"] & V\arrow[d, "a"]\\
V\arrow[r, "b"] & V
\end{tikzcd}
\]
De aquí deducimos que la multiplicación por $b$ es un morfismo de representaciones. Por tanto, $b=\lambda_b Id$ en virtud del lema de Schur, es decir, la multiplicación por $b$ es la multiplicación por un número $\lambda_b\in k$. Supongamos que $V$ tuviera dimensión al menos 2. Podemos escoger dos vectores linealmente independientes $u,v$. Entonces cada recta $\gene{u}$ y $\gene{v}$ son subrepresentaciones de $V$, pues son cerradas para el producto escalar. Esto es una contradicción con el hecho de que $V$ sea irreducible. 
\end{solucion}

\newpage

\begin{ejercicio}{2}
Hallar una representación irreducible de dimensión 2 de $\R[x]$. 
\end{ejercicio}
\begin{solucion}
Tenemos que definir $\rho:\R[x]\to \End(\C)$ viendo $\C$ como $\R$-espacio vectorial. Definimos el homomorfismo de álgebras inducido por extensión lineal de $x\mapsto i$ (multiplicación por $i$). Como no hay ningún subespacio propio no trivial invariante por esta multiplicación, la representación es irreducible.  
\end{solucion}

\newpage

\begin{ejercicio}{3}
Si en $\End_A(V)$ hay solamente la identidad y sus múltiplos, entonces $V$ es indecomponible.
\end{ejercicio}
\begin{solucion}
Supongamos que existen una subrepresentaciones $W_1,W_2\subset V$ tales que $W_1\oplus W_2= V$. Dado $v\in V$, podemos descomponerlo de forma única como $v=w_1+w_2$, donde $w_1\in W_1$ y $w_2\in W_2$. Es fácil comprobar que las proyecciones $p_i:V\to W_i$ son morfismos de representaciones, pero $p_i$ es un múltiplo de la identidad si y solo si $W_i=V$ o bien $W_i=0$. 
\end{solucion}
\newpage
\begin{ejercicio}{4}
Sea $G$ un grupo y sea $k[G]$ el álgebra asociada. Sabemos que entre $k[G]$ y el espacio de las funciones sobre $G$, $\mathcal{F}(G,k)$ hay un isomorfismo de espacios vectoriales dado por
$$
F = \sum_{g\in G} a_h g - g\to a_g
 \sum_{g\in G} a_g g \mapsto (g\mapsto a_g)
$$
Calcular el centro de $k[G]$ en términos de $\mathcal{F}(G,k)$. 
\end{ejercicio}
\begin{solucion}
Si $x\in Z(k[G])$ entonces $hx=xh$ para todo $h\in G$ (de hecho el recíproco también es cierto). Equivalentemente, $x=hxh^{-1}$. Escribiendo $x=\sum_{g\in G}a_gg$ deducimos que $a_g=a_{hgh^{-1}}$ para todo $h\in G$. Efectivamente, tenemos para cada $h$ fijo
\[
\sum_{g\in G}a_gg=\sum_{g\in G}a_g hgh^{-1}
\]
Haciendo un cambio de variable $u=hgh^{-1}$ obtenemos la igualdad
\[
\sum_{u\in G}a_uu=\sum_{u\in G}a_{huh^{-1}} u
\]
por lo que se tiene la igualdad de coeficientes que buscábamos. La conclusión es que $x\in Z(k[G])$ si y solo si los coeficientes $a_g$ son constantes en la clase de conjugación de $g$. 
Sea $f\in k[G]$. Es claro que $f$ está en el centro si y solo si conmuta con cada elemento de $G$. Sea $h\in G$. Tenemos
\begin{align*}
fh =  hf &\Longrightarrow \left(\sum_{g\in G} a_g g \right)h = h\left(\sum_{g\in G} a_g g \right)\\
&\Longrightarrow \sum_{g \in G} a_g (gh) = \sum_{g \in G} a_g (hg) \\
&\Longrightarrow \sum_{g \in G} a_g (gh)h^{-1} = \sum_{g \in G} a_g (hg) h^{-1}\\
&\Longrightarrow \sum_{g \in G} a_g g = \sum_{g \in G} a_g (hgh^{-1}) 
\end{align*}
Por tanto, la condición necesaria y suficiente que es que $a_g$ sea constante entre los miembros de una misma clase de conjugación.
\end{solucion}
\newpage

\section{Ejercicios del libro}

\begin{ejercicio}{1.20}
Sea $V$ una representación vectorial no trivial de dimensión finita de un álgebra $A$. Probar que tiene una subrepresentación irreducible. Probar entonces con un ejemplo que esto no siempre se cumple para representaciones de dimensión infinita.
\end{ejercicio}
\begin{solucion}
Si $V$ es irreducible, ya está. Si no, entonces tiene alguna subrepresentación propia $V_1$ no trivial de dimensión estrictamente menor. Repetimos recursivamente sobre este procedimiento con $V_1$ y como la dimensión es finita, el proceso termina, dando una subrepresentación irreducible.

Construimos ahora un contraejemplo para el caso de dimensión infinita. Sea $A=\C[x]$ y consideramos la representación regular (Ejemplo 1.10) de $A$ actuando sobre sí mismo con la multiplicación del anillo. Entonces cualquier elemento no nulo de $A$ genera una subrepresentación isomorfa a $A$, por lo que no puede tener subrepresentaciones irreducibles. 

%Sea $A=\C[C_\infty]$ el álgebra del grupo cíclico infinito $C_\infty=\gene{c}$. Sea $V=\C[T,T^{-1}]$ el anillo de polinomios de Laurent, es decir, 
%\[
%V=\{a(T)=\sum_{i=m}^n a_iT^i\mid m,n\in\Z, m\leq n, a_i\in\C\}
%\]
%
%Podemos convertir $V$ en un $A$-módulo haciendo que el elemento $c^j\in C_\infty$ ($j\in\Z$) actúe con una traslación de $j$ posiciones, es decir,
%\[
%c^j\cdot a(T)=T^ja(T)
%\]
%Veamos que $V$ no contiene submódulos irreducibles. Supongamos por el contrario que existe un submódulo irreducible $W\neq\{0\}$. Si $a(T)=\sum_{i=m}^n a_iT^i\neq 0$ tiene $a_m\neq 0\neq a_n$, entonces llamamos a $|n-m|$ la \emph{anchura} de $a(T)$. Por tanto, todos los elementos no nulos de $V$ tienen anchura positiva. Esto implica que todo submódulo de $V$ contiene elementos de anchura mínima. Pero si $W$ es un submódulo irreducible, entonces el espacio $(T-1)W=\{(T-1)a(T)\mid a(T)\in W\}$ es un subespacio de $W$. 
%
%ME FALTA EL CONTRAEJEMPLO
%\url{https://math.stackexchange.com/questions/1041759/infinite-dimensional-representation-such-that-every-subrepresentation-is-reducib} (prefiero el segundo)
\end{solucion}

\newpage

\begin{ejercicio}{1.21}
Sea $A$ un álgebra sobre un cuerpo $k$ algebraicamente cerrado. El centro $Z(A)$ de $A$ es el conjunto de los elementos $z\in A$ que conmutan con todos los elementos de $A$. 
\begin{enumerate}[(a)]
\item  Probar que si $V$ es una representación irreducible de dimensión finita de $A$, entonces cualquier elemento $z\in Z(A)$ actúa en $V$ como multiplicación por algún escalar $\chi_V(z)$. Probar que $\chi_V:Z(A)\to k$ es un homomorfismo. Se llama \textbf{caracter central} de $V$.

\item Probar que si $V$ es una representación de dimensión finita indecomponible de $A$, entonces para cualquier $z\in Z(A)$, el operador $\rho(z)$ por el cual $z$ actúa en $V$ tiene solo un autovalor $\chi_V(z)$, igual al escalar por el cual $z$ actúa en alguna subrepresentación irreducible de $V$. Por tanto, $\chi_V:Z(A)\to k$ es un homomorfismo, que se llama de nuevo caracter central de $V$.

\item ¿Es $\rho(z)$ necesariamente un operador escalar?

\end{enumerate}
\end{ejercicio}
\begin{solucion}
\begin{enumerate}[(a)]
\item[]
\item Si $z$ conmuta con todos los elementos de $A$, naturalmente para $v\in V$ y $a\in A$
$$
z(av) = za(v) = az(v)=a(zv)
$$ 
Por lo que mutiplicar por $z$ es un morfismo de representaciones. Por la hipótesis de que $V$ es irreducible y de dimensión finita, y al ser $k$ algebraicamente cerrado, deducimos del Lema de Schur que $\exists \X_V(z) \in k$ tal que $\rho(z)=\X_V(z)Id$.

Es claro que $Z(A)$ es una subálgebra, pues la unidad está y si $z,w$ conmutan con todo $A$, también lo hacen $z+w,zw,sz$ también lo hacen, con $s\in k$. Para ver que $\X_V(z)$ es un morfismo de álgebras (viendo $k$ como álgebra), sean $z,w\in Z(A)$, $s \in k$, entonces
\begin{align*}
\rho(z+w) &= \rho(z)+\rho(w) = \X_V(z)Id + \X_V(w)Id = (\X_V(z)+\X_V(w))Id \\
\rho(sz) &= s\rho(z) = s\X_V(z)Id = (s\X_V(z))Id\\
\rho(1_A)&=Id = (1_k)Id\\
\rho(zw) &= \rho(z)(\rho(w)) =\rho(z)(\X_V(w)Id) = \X_V(z)Id\X_V(w)Id = \X_V(z)\X_V(w)Id
\end{align*}
\item Tenemos que para todo $z\in Z(A)$ y todo $\lambda\in k$,  se verifica que, $\forall a \in A$ y $v \in V$
\begin{align*}
(\rho(z)-\lambda Id)(\rho(a)(v)) &= \rho(z)\circ \rho(a)(v) - \lambda Id (\rho(a)(v)) \\
&= \rho(za)(v) - \lambda \rho(a)(v)\\
&= \rho(az)(v) - \lambda \rho(a) \circ Id (v)\\
&= \rho(a) \circ \rho(z)(v) - \lambda \rho(a)\circ Id(v)\\
&= \rho(a)\circ ( \rho(z) - \lambda Id) (v)
\end{align*}
Por tanto, $\rho(z)-\lambda Id$ es un morfismo de representaciones. En particular, si $v$ es el autovector asociado a un autovalor $\lambda$, 

$$(\rho(z)-\lambda Id)(av)=a(\rho(z)-\lambda Id)(v)=0.$$

En particular, el espacio $V_1(\lambda)$ de autovectores asociados al autovalor $\lambda$ es invariante por esta representación, luego $V_1(\lambda)$ es una subrepresentación. Recordemos que autovectores asociados a distintos autovalores son linealmente independientes y suman, con suma directa, el espacio total por ser $k$ algebraicamente cerrado. Si hay $n$ autovalores distintos $\lambda_1,\dots, \lambda_n$ (debe haber una cantidad finita porque la representación es finita), entonces $V=\bigoplus_i V_{\lambda_i}$, donde $V_{\lambda_i}$ es el autoespacio asociado a $\lambda_i$. Como $V$ es indecomponible, necesariamente $n=1$.


\item No, para $A=k[x]$ ($Z(A)=A$) tras el ejemplo 1.19 se explica que $\rho(z)$ puede ser cualquier bloque de Jordan, por lo que en general no será necesariamente escalar. 

\end{enumerate}
\end{solucion}

\newpage

\begin{ejercicio}{1.22}
Sea $A$ un álgebra asociativa y $V$ una representación de $A$. Denotamos por $\End_A(V)$ al álgebra de morfismos de representaciones $V\to V$. Probar que $\End_A(A)=A^{op}$, el álgebra $A$ con la multiplicación opuesta.
\end{ejercicio}
\begin{solucion}
Definimos la aplicación $A^{op}\to \End_A(A)$ mediante $a\mapsto f_a \equiv (x\mapsto xa)$. Probamos que esta aplicacion es un morfismo de álgebras. Es claro que se trata de una aplicación lineal, por lo que comprobamos solamente que respeta el producto, que denotamos $a*b$, que por definición es $ba$. Tenemos por definición $a*b\mapsto f_{a*b}(x\mapsto x(a*b)=x(ba))$.

Veamos entonces que $f_a\circ f_b=f_{a*b}=f_{ba}$. 
\[
f_a(f_b(x))=f_a(xb)=xba=x(ba)
\]
por lo que la aplicación es un morfismo de álgebras. De hecho preserva la unidad puesto que trivialmente $1\mapsto Id_A$. Además tiene inverso dado por $f\mapsto f(1)$. Es fácil comprobar que efectivamente es el inverso, por lo que tenemos un isomorfismo. 
\end{solucion}

\newpage
\begin{ejercicio}{1.23}
Probar el siguiente ``lema infinito-dimensional de Schur'' (debido a Dixmier): sea $A$ un álgebra sobre $\C$ y $V$ una representación irreducible de $A$ con una base numerable. Entonces cualquier morfismo de representaciones $\phi:V\to V$ es un operador escalar.

Pista. Por el lemma de Schur usual, el álgebra $D=\End_A(V)$ es un álgebra con división. Probar que $D$ es como mucho de dimensión numerable. Suponer que $\phi$ no es escalar y considerar un subcuerpo $\C(\phi)\subset D$. Probar que $\C(\phi)$ es extensión trascendental de $\C$. Deducir de esto que $\C(\phi)$  tiene dimensión no numerable y obtener una contradicción.
\end{ejercicio}
\begin{solucion}
Primero aclaremos por qué $D$ es un álgebra de división.
Como $V$ es irreducible, todo homomorfismo no nulo de $V \to V$ debe ser un isomorfismo por el lema de Schur.
En otras palabras, todo elemento no nulo de $\End_A(V)$ debe poseer inverso.

Sea $v$ un generador de la representación irreducible $V$ de manera que $A \cdot v = V$.
Sea consideramos el morfismo de espacios vectoriales:
\[ \alpha : D \to V\qquad f \mapsto f(v) \]
Para todo $w \in V$, existe $a \in A$ tal que $w = a \cdot v$ (o lo que es lo mismo, $\rho(a)(v)$), entonces:
\[ f(w) = f(a\cdot v) = a f(v) \]
Luego $f(v)$ determina $f$ y $\alpha$ es inyectiva, luego:
\[ \dim D = \dim \End_A(V) \leq \dim V \]
Como $V$ tiene dimensión numerable, $D$ también tiene dimensión numerable.

Supongamos que $\phi$ no es un operador escalar y consideremos la extensión de cuerpo $\C(\phi)$.
Veamos por reducción al absurdo que $\phi$ no es elemento algebraico sobre $\C$.
Si lo fuera, entonces habría unos coeficientes $a_{n-1},\dots,a_1,a_0 \in \C$ tales que:
\[ \phi^n + a_{n-1}\phi^{n-1} + \dots + a_1 \phi + a_0 1 = 0 \]
Como $\C$ es algebraicamente cerrado, podemos reescribir esta ecuación como:
\[ (\phi-c_1 1)(\phi-c_2 1) \cdots (\phi-c_n 1) = 0_V \]
Para ciertos $c_1,\dots,c_n \in C$.
Entonces existe $c_i$ tal que $\phi = c_i 1$, lo que implicaría que $\phi$ es operador escalar y sería un absurdo.

Luego $\C(\phi)$ es una extensión trascendente.
Para ver que $\C(\phi)$ es de dimensión incontable, basta tomar un conjunto linealmente independiente de cardinalidad incontable:
\[ \left\{\frac{1}{\phi - c 1} \mid c \in \C\right\} \]

Veamos que es linealmente independiente.
Supóngase que hubiera existieran $c_1,\dots,c_n \in \C$ distintos y $a_1,\dots,a_n \in \C^*$ tal que:
\[ \frac{a_1}{\phi - c_1 1} + \dots + \frac{a_n}{\phi - c_n 1} = 0 \]
Entonces, eliminando denominadores:
\[ \sum_{i=1}^n \left(a_i \prod_{j\neq i}(\phi - c_j 1)\right) = 0\]
Podemos decir que este es un polinomio en $\phi$ de grado $n-1$ porque cada $\prod_{j\neq i}(\phi - c_j 1)$ es distinto, por lo que no hay unos $a_i$ que anulen la suma.
Pero es un absurdo, ya que $\phi$ es transcendente y no puede ser raíz de un polinomio.

Entonces, como $\{\frac{1}{\phi - c 1} \mid c \in \C\}$ está contenido $\C(\phi)$, esto implica $\C(\phi)$ es de dimensión innumerable.
Ahora llegamos al absurdo, pues $\C(\phi) \subset D$, pero $\C(\phi)$ es innumerable y $D$ es numerable.
Esto implica que nuestra hipótesis que $\phi$ no es operador escalar es falsa, lo que demuestra el teorema.
\end{solucion}

\newpage




\begin{ejercicio}{1.24}
Sea $A = k[x_1,\dotsc,x_n]$ y sea $I\neq A$ un ideal de $A$ que contiene todos los polinomios homogéneos de grado $\geq N$. Demostrar que $A/I$ es una representación indecomponible de $A$. 
\end{ejercicio}
\begin{solucion}
Consideremos la acción $\rho(a)(v) = \pi(a)\pi(v)$ donde $\pi$ es la aplicación de paso al cociente. Claramente $\pi$ es $k$-lineal y es compatible con el producto, además
$$
\rho(ab)(v) = \pi(ab)\pi(v) =\pi(a)\pi(bv) = \rho(a)\circ \rho(b)(v)
$$
Por tanto, $A/I$ es una representación de $A$. Para ver que es indecomponible, consideremos una base de $A/I$. Esta esta formada por las proyecciones de los monomios en $x_1,\dotsc,x_n$. Sea $W_1,\dotsc,W_k$ una desomposición propia en suma directa de $A/I$. $\exists! i$ tal que $\pi(1)\in W_i$. Tiene que existir un monomio $\overline{x}_1,\dotsc,\overline{x}_n$ que no pertenezca a $W_i$, pues en otro caso $W_i = A/I$. Supongamos sin pérdida de generalidad que es $\overline{x}_k$. En tal caso
$$
\rho(x_k)(1) = \pi(1)\pi(x_k) = \overline{x}_k \notin W_i
$$
Por tanto, $W_i$ no es subrepresentación. Como esto es independiente de la descomposición escogida, $A/I$ es una representación indecomponible.
\end{solucion}


\newpage

\begin{ejercicio}{1.25}\label{25}
Sea $V\neq 0$ una representación de $A$. Decimos que un vector $v$ es cíclico si genera $V$, es decir, si $V= Av$. Una representación que admita un vector cíclico se dice cíclica. Demuestra que
\begin{enumerate}[(a)]
\item $V$ es irreducible si y solo si todos los vectores no nulos son cíclicos.
\item $V$ es cíclico si y solo si es isomorfo a $A/I$, donde $I$ es algún ideal de $A$. 
\item Da un ejemplo de una representación indecomponible que no sea cíclica.

\end{enumerate}
\end{ejercicio}
\begin{solucion}
\begin{enumerate}[(a)]
\item[]
\item Supongamos que $V$ es irreducible. Supongamos por reducción al absurdo que $\exists w$ no cíclico. En ese caso $Aw$ está estrictamente contenido en $V$ y, además, es un subespacio vectorial. Además, para todo $z \in Aw$ existe $b \in A$ tal que $\forall a \in A$ se cumple
$$
\rho(a)(z) = \rho(a)\circ \rho(b) (w) = \rho(ab) (w) \in Aw
$$
Por tanto, $Aw$ es una subrepresentación de $A$, lo cuál es una contradicción.


Recíprocamente, supongamos que todos los vectores no nulos son cíclicos. Si $V$ no es irreducible debe existir $W\subset V$ que sea subrepresentación, es decir, que $AW\subset W$. Sea $w\in W$ no nulos y sea $v \notin W$, debe existir un $a \in A$ tal que $aw = v$, lo cuál es una contradicción.
\item Supongamos que $V$ es cíclico. Entonces existe $v\in V$ tal que $Av = V$. Consideramos el morfismo de $A$-módulos $\phi=\rho(-)(v):A\to V$ definido como $a\mapsto \rho(a)(v)=av$. Como $Av=V$, este morfismo es sobreyectivo, y para $I=\ker\phi$ se tiene que $A/I\cong V$. Este isomorfismo es como $A$-módulos, pero $I$ no es solo un submódulo sino que es un ideal de $A$. 

El recíproco es trivial porque basta considerar la imagen de $\overline{1}\in A/I$ mediante el isomorfismo $A/I\cong V$. 

\item Sea $A = \C[x,y]/I_2$, visto como $\C$-ev (intuyo), donde $I_2$ es el ideal generado por los polinomios homogéneos de grado $\geq 2$ y $V = A^*$ donde $A^*$ es el espacio de los funcionales lineales de $A$ con la acción dada por $\rho(a)(f)(b) = f(ba)$. 

Veamos primeramente que $V$ no puede tener vectores cíclicos. Sea $f \in A^*$ no nulo, entonces 

Para ver que $V$ es indecomponible, sea $W_1,\dotsc,W_s$ tales que $V = \bigoplus_{i=1}^s W_i$. 
\end{enumerate}
\end{solucion}

\newpage

\begin{ejercicio}{1.26}
Let $A$ be the Weyl algebra, generated by two elements $x,y$ with the relation
\[ yx - xy - 1 = 0 \]
\begin{enumerate}[(a)]
\item If $\text{char} k = 0$, what are the finite dimensional representations of $A$? What are the two-sided ideals in $A$?

Hint. For the first question, use the fact that for two square matrices $B,C$, $Tr(BC) = Tr(CB)$. For the second question, show that any nonzero two-sided ideal in $A$ contains a nonzero polynomial in $x$, and use this to characterize this ideal.

Suppose for the rest of the problem that $\text{char} k = p$.
\item What is the center of $A$?

Hint. Show that $x^p$ and $y^p$ are central elements.

\item Find all irreducible finite dimensional representations of $A$.

Hint. Let $V$ be an irreducible finite dimensional representation of $A$, and $v$ be an eigenvector of $y$ in $V$. Show that $\{x, xv, x^2v, \dots, x^{p-1}v\}$ is a basis of $V$.
\end{enumerate}
\end{ejercicio}
\begin{solucion}(Solución de \href{https://ferngaston.wordpress.com/2016/06/30/representations-of-the-weyl-algebra/}{ferngaston} con mejoras)

\begin{enumerate}[(a)]
\item
Si la característica del cuerpo $k$ es cero, entonces no hay representaciones de dimensión finita no triviales de $A$, ya que en tal representación $x, y$ deben actuar como matrices y la identidad $[x,y]=1$ no puede darse, porque el conmutador de dos matrices tiene traza nula $Tr([x,y])=0$, pero $Tr(I)\neq 0$.

Es fácil probar por inducción que $y^jx = xy^j + jy^{j-1}$.
Supóngase que $I$ es un ideal bilateral de $A$ que contiene un elemento no nulo $p(x,y)$ donde $x$ e $y$ aparecen con coeficientes no nulos.
Con la identidad anterior podemos ver que $xp-px = p'(y)$, donde $p'$ es la derivada formal de $p$ respecto a $y$ evaluada en $x=1$.
De esta forma, podemos encontrar siempre un polinomio $q$ que dependa sólo de $y$.
Análogamente, usando que $x^jy = yx^j + jx^{j-1}$ llegamos a que siempre existe un polinomio $q$ que dependa sólo de $x$.

Tomando un polinomio $q(x) \in I$, entonces, $I \ni yq-qy = q(1)$, que es una unidad del álgebra.
Luego el único ideal no nulo es todo el álgebra.
Con esto también podríamos haber demostrado que $A$ no tenga representaciones finita no triviales, pues tal representación estaría dado por un morfismo de álgebras $A \to \End_k(V)$, que claramente tiene un kernel no trivial.
Dicho kernel, al ser un ideal, sería todo $A$.
En particular, su unidad debe actuar como el endomorfismo $0$, lo que implica que $V = 0$.

\item
Supongamos ahora que nuestra base tiene característica $p$.
Es fácil ver que $x^p$ e $y^p$ son centrales, ya que $y^px = xy^p + py^{p-1} = xy^p$.
Vamos a ver que el centro es el ideal $(x^p,y^p)$.
Si no fuera así, tomemos $q$ un polinomio no contenido en este ideal.
Sin pérdida de generalidad podemos asumir que hay un término de la forma $x^iy^j$ tal que $p$ no divide a $j$.
Entonces $xq-qx = q'(y)$ donde $q'$ es un polinomio no nulo, luego $q$ no es central.

\item
Busquemos ahora todas las representaciones irreducibles de dimensión finita de $A$.
Tomando las trazas de la identidad $xy-yx=1$, concluímos que toda representación de dimensión finita $V$ debe ser de dimensión divisible por $p$, digamos $np$.

Sea $v \in V$ un autovector de $y$, es decir con $yv = \lambda v$. Por el problema $1.25$, como $V$ es irreducible, $v$ es cíclico y genera $V=Av$.
Veremos que de hecho podemos ignorar los monomios con $y$:
\[ V = \langle v, xv, x^2v, \dots \rangle \]
Ya que:
\begin{equation}\label{ejer126-eq1} y \sum \mu_i x^i v = \sum\left(\mu_i \lambda x^i v + i \mu_i x^{i-1}v \right) \end{equation}

Por otro lado, por el problema $1.21$, existe un elemento central $\mu$ para $x^p$ tal que $x^pv=\mu v$. Por lo tanto:
\[ V = \langle v, xv, \dots, x^{p-1}v\rangle \]

La acción de $x$ está dada por la matriz:
\[ x = \begin{bmatrix}
0 & 0 & 0 & \dots & 0 & \mu\\
1 & 0 & 0 & \dots & 0 & 0\\
0 & 1 & 0 & \dots & 0 & 0\\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
0 & 0 & 0 & \dots & 1 & 0
\end{bmatrix}\]
De la ecuación \eqref{ejer126-eq1} deducimos que la acción de $y$ está dada por la matriz:
\[ y = \begin{bmatrix}
\lambda & 1 & 0 & \dots & 0\\
0 & \lambda & 2 & \dots & 0\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
0 & 0 & 0 & \dots & p-1\\
0 & 0 & 0 & \dots & \lambda
\end{bmatrix}\]

Distintas elecciones de $\lambda$ y $\mu$ dan representaciones irreducibles de dimensión finita no isomorfas.
\end{enumerate}
\end{solucion}

\newpage

\begin{ejercicio}{1.27}
Let $q$ be a nonzero complex number, and $A$ be the $q$-Weyl algebra over $\C$ generated by $x^{\pm 1}$ and $y^{\pm 1}$ with defining relations $xx^{-1} = x^{-1}x = 1$, $yy^{-1} = y^{-1}y =1$ and $xy = qyx$.
\begin{enumerate}[(a)]
\item What is the center of $A$ for different $q$? If $q$ is not a root of unity, what are the two-sided ideals in $A$?
\item For which $q$ does this algebra have finite dimensional representations?\\
Hint. Use determinants.
\item Find all finite dimensional irreducible representations of $A$ for such $q$.\\
Hint. This is similar to part (c) of the previous problem.
\end{enumerate}
\end{ejercicio}

\begin{solucion}
Este álgebra es más conocida como \textit{quantum torus}, \textit{twisted Laurent polynomial algebra}, \textit{multiplicative analogue of the Weyl algebra} o \textit{McConnell–Pettit algebra}.

\begin{enumerate}[(a)]
\item Denotemos $Z(A)_q$ el centro del álgebra de $q$-Weyl. Si $q=1$ entonces es claro que $Z(A)_1 = A$.
En otro caso, si $q$ es una $n$-raíz de la unidad, tenemos que:
\[ xy^j = q^jy^jx \]
\begin{equation}\label{ejer127-eq1} x^jy = q^jyx^j 
\end{equation}
Luego sii $j=kn$, tenemos que $[x,y^{kn}]=[x^{kn},y]=0$.
Entonces el centro es $Z(A)_q = k[x^n,y^n,x^{-n},y^{-n}]$.
Si $q$ no es una raíz de la unidad, entonces ningún monomio commuta y el centro es $\C$.

Si $q$ no es raíz de la unidad, los únicos ideales bilaterales son los ideales $\{0\}$ y $A$, es decir, $A$ es un álgebra simple. Para probarlo, sea $I$ un ideal. Sea $f \in I$, es claro que multiplicando adecuadamente por algún monomio $x^i y^j$, $x^i y^j f$ será un polinomio en el que todos las variables aparecen con grado no negativo. Entre todos estos polinomios, consideremos $p = p(x,y) = \sum a_{ij}x^i y^j$ de grado mínimo $d$ usando orden graded lexicographic order. Sea $h$ el grado en $x$ de este monomio. Si su $d= 0$, hemos acabado. Supongamos que $d>0$ y $h>0$. Notemos que por minimalidad $p$ ha de tener término independiente. Ahora bien, es fácil comprobar que
$$
y^{-1}(x^i y^j)y = q^i x^i y^j
$$
Dado que $q$ no es raíz de la unidad, $q^hp - y^{-1}py \in I$ es un polinomio en $x,y$ no nulo y tiene grado menor que $q$, lo cuál es una contradicción. Si $h=0$ se puede razonar análogamente con $x^{-1}px$.
\item Consideramos una representación de dimensión $n$ del álgebra.
Tomamos determinante de $xy=qyx$:
\[ |xy| = |qyx| \Rightarrow |x||y| = q^n |y||x| \Rightarrow q^n = 1 \]
Luego tiene representación finita si y sólo si $q$ es raíz de la unidad.

\item Por la ecuación anterior se deduce que si $q^m=1$, entonces las representaciones de dimensión finita de $A$ son de dimensión $n=km$.

Supongamos ahora que $V$ es irreducible.
Sea $v \in V$ un autovector de $y$, es decir con $yv = \lambda v$.
Por el problema $1.25$, como $V$ es irreducible, $v$ es cíclico y genera $V=Av$.

Dado que podemos escribir cualquier elemento de $A$ en la forma:
\[ \sum c_{ij} x^i y^j \]
y que $y^jv = \lambda^j v$ para todo $j \in \Z$, entonces $V$ está generado por los vectores $\{x^iv \mid i \in \Z\}$.
Por otro lado, por el problema $1.21$, existe un elemento central $\mu$ para $x^n$ tal que $x^nv=\mu v$.
Además:
\[ x^{-n+l}v = x^{l}x^{-n}v = x^l\mu^{-1} v \]
Por lo tanto, podemos ignorar también los vectores donde intervienen los monomios con exponentes negativos:
\[ V = \langle v, xv, \dots x^{n-1}v \rangle \]

La acción de $x$ está dada por la matriz:
\[ x = \begin{bmatrix}
0 & 0 & 0 & \dots & 0 & \mu\\
1 & 0 & 0 & \dots & 0 & 0\\
0 & 1 & 0 & \dots & 0 & 0\\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
0 & 0 & 0 & \dots & 1 & 0
\end{bmatrix}\]

La acción de $y$ se deduce de \eqref{ejer127-eq1}, dada por la matriz:
\[ y = \begin{bmatrix}
\lambda & 0 & \dots & 0 & 0\\
0 & q^{-1}\lambda & \dots & 0 & 0\\
\vdots & \vdots & \ddots & \vdots & \vdots\\
0 & 0 & \dots & q^{-n+2} \lambda & 0\\
0 & 0 & \dots & 0 & q^{-n+1} \lambda
\end{bmatrix}\]
\end{enumerate}
\end{solucion}

\newpage
\begin{ejercicio}{1.33}
Show that the algebra $P_Q$ is generated by $p_i$ for $i ∈ I$ and $a_h$ for $h ∈ E$ with the
defining relations:
\begin{enumerate}
\item $p^2_i = p_i$, $p_ip_j = 0$ for $i\neq j$
\item $a_hp_{h′} = a_h$, $a_hp_j = 0$ for $j\neq h′$
\item $p_{{h'}'}a_h = a_h$, $p_ia_h = 0$ for $i\neq h''$
\end{enumerate}
\end{ejercicio}
\begin{solucion}
Basta observar que cualquier camino $a\in P_Q$ se descompone de forma única como concatenación de caminos del tipo $a_h$ de longitud 1 entre vértices $h'$ y $h''$, que claramente verifican las relaciones del enunciado. Que los $p_i$ verifican la primera relación es trivial. 
\end{solucion}

\newpage
\begin{ejercicio}{1.34}
Let $A$ be a $\Z^+$-graded algebra, i.e., $A = \bigoplus_{n≥0}A[n]$, and $A[n]A[m] ⊂ A[n + m]$. If $A[n]$ is finite dimensional, it is useful to consider the Hilbert series $h_A(t) = \sum \dim(A[n])t^n$ (the generating function of dimensions of $A[n]$). Often this series converges to a rational function, and the answer is written in the form of such function. For example, if $A = k[x]$ and $deg(x^n) = n$ then
$$
h_A(t) = 1 + t + t^2 + \dotsc  + t^n + \dotsc  = \frac{1}{1-t}
$$
Find the Hilbert series of:
\begin{enumerate}[a)]
\item $A = k[x_1,\dotsc, x_m]$ (where the grading is by degree of polynomials);
\item $A = k \gene{ x_1, \dotsc , x_m}$ (the grading is by length of words);
\item $A$ is the exterior (=Grassmann) algebra $∧_k[x_1, \dotsc , x_m]$, generated over some field $k$ by $x_1, \dotsc , x_m$ with the defining relations $x_ix_j + x_jx_i = 0$ and $x^2_i = 0$ for all $i, j$ (the grading is by degree).
\item $A$ is the path algebra $P_Q$	of a quiver $Q$ (the grading is defined by $deg(p_i) = 0$, $deg(a_h) = 1$).
Hint. The closed answer is written in terms of the adjacency matrix $M_Q$ of $Q$.
\end{enumerate}
\end{ejercicio}
\begin{solucion}
\begin{enumerate}[a)]
\item[]
\item Sea $A[i]$ el grupo abeliano de los polinomios homogéneos de grado $i$, entonces $A= \bigoplus_{n\geq 0}A[n]$ y $A[n]A[m]\subset A[n+m]$. Además, una base de estos grupos vistos como $k$-ev. está dada por todos los monomios de grado $i$. Esta base tiene dimensión
$$
\binom{n-1+i}{i} = \frac{(m-1+i)!}{i!(m-1)!}
$$
Por tanto
$$
h_A(t) = \sum_{i=0}^\infty \frac{(m-1+i)!}{i!(m-1)!} t^i = \frac{1}{(1-t)^m}
$$
\item Este caso es análogo al anterior, solo que en este nos importa el orden de la multiplicación, de manera que $x^2y^2 \neq xyxy$. Por tanto, el número de monomios de grado $i$ es $m^i$. 
$$
h_A(t) = \sum_{i=0}^\infty n^i t^i = \frac{1}{1-mt} 
$$
\item Es una cuestión puramente conmbinatoria comprobar que el número de moniomos de grado $n$ es $\binom{m}{i}$ si $i\leq m$ y $0$ en otro caso, luego
$$
h_A(t) = \sum_{n\geq 0} \dim(A[n])t^n = \sum_{n=0}^m \binom{m}{n}t^n = (t+1)^m
$$
\item Consideremos $A[n]$ como el espacio vectorial generado por caminos entre cualesquiera vértices que tienen longitud (y por tanto, grado) $n$. Esos caminos están precisamente dados por la suma de todos los elementos de $M_Q^n$. Por tanto, considerando $|\cdot|$ la suma de los elementos de la matriz, entonces
$$
h_A(t) = \sum_{n\geq 0} \dim(A[n])t^n =  \sum_{n\geq 0}1_n'M_Q^n1_nt^n = 1_n' \left(\sum_{n\geq 0} (tM_Q)^n \right)1_n = 1'_n (I-tM_Q)^{-1}1_n
$$
Nótese que el caso $n=0$ está correctamente definido.
\end{enumerate}
\end{solucion}

\begin{solucion}(Alternativa)
\begin{enumerate}[(a)]
\item
Escribiremos $A^m$ para referirnos a $k[x_1,\dots,x_m]$.
Demostraremos por inducción en $m$ que
\begin{equation}\label{ejer134-eq1} h_{A^m}(t) = \frac{1}{(1-t)^m} \end{equation}
Para $m=1$, ya sabemos que $h_{A^1}(t) = 1/(1-t)$.
Suponemos cierta la ecuación \eqref{ejer134-eq1} y tratamos de demostrar el paso de inducción para $m+1$.
Sea $n \in \N$ y obsérvese que la base de $A^{m+1}[n]$ como espacio vectorial puede ser a su vez <<graduada>> por el grado de $x_{m+1}$. Entonces:
\[ \dim A^{m+1}[n] = \sum_{j=0}^{n} \dim A^m[j] = \sum_{j=0}^n c_j\]
donde $c_j$ es el coeficiente de $1/(1-t)^m$ en $t^j$.
Entonces usando lo que sabemos de producto de series:
\[ h_{A^{m+1}}(t) = \sum_{i=0}^{\infty}\sum_{j=0}^i c_jt^i = \left(\sum_{j=0}^{\infty}c_jt^j\right)\left(\sum_{i=0}^{\infty}t^i\right) = \frac{1}{(1-t)^m} \frac{1}{1-t} = \frac{1}{(1-t)^{m+1}}\]
\end{enumerate}
\end{solucion}
\newpage

\begin{ejercicio}{}
Show that Example 1 is a special case of Example 5 (for $n = 3$).
\end{ejercicio}
\begin{solucion}
El ejemplo 	1 es $(\R^3,\times)$, donde $\times$ denota el producto vectorial. El ejemplo 5 es $\mathfrak{so}(n)$, las matrices $n\times n$ antisimétricas con corchete $[a,b]=ab-ba$. Para $n=3$, $\mathfrak{so}(3)\cong \R^3$ como espacio vectorial. Basta comprobar que el corchete es equivalente al producto vectorial para la base canónica mediante la siguiente identificación
\[(1,0,0)\mapsto 
\begin{pmatrix}
0 & 1 & 0\\
-1& 0 & 0\\
0 & 0 & 0
\end{pmatrix}, (0,1,0)\mapsto \begin{pmatrix}
0 & 0 & -1\\
0 & 0 & 0\\
1 & 0 & 0
\end{pmatrix}, (0,0,1)\mapsto\begin{pmatrix}
0 & 0 & 0\\
0 & 0 & 1\\
0 & -1& 0
\end{pmatrix}
\]
lo cual es un sencillo cálculo matricial. Para el resto de vectores, la distributividad y $\R$-linealidad del producto permite reducirlo a la base canónica.
\end{solucion}
\newpage

\begin{ejercicio}{}
Explain why a representation of a Lie algebra is the same thing as a representation
of its universal enveloping algebra.
\end{ejercicio}
\begin{solucion}
Sea $\mathfrak{g}$ un álgebra de Lie con base $x_i$ y con corchete definido como $[x_i,x_j]=\sum_k c_{ij}^kx_k$. Cualquier representación $\rho:\mathfrak{g}\to\gl(V)$ debe verificar $\rho([x_i,x_j])=[\rho(x_i),\rho(x_j)]=\sum_kc_{ij}\rho(x_k)$. Por tanto, las representaciones de $\g$ están en biyección con las familias $(y_i)$ de elementos de $\gl(V)$ que verifican $[y_i,y_j]=\sum_k c_{ij}y_k$, que son las posibles imágenes de $\rho(x_i)$. Por la propiedad universal del cociente, estas familias están en biyección con las representaciones de $U(\g)$. 
\end{solucion}

\newpage

\begin{ejercicio}{1.55}
According to the above, a representation of $\mathfrak{sl}(2)$ is just a vector space $V$ with a
triple of operators $E$, $F$, $H$ such that $HE − EH = 2E$, $HF − FH = −2F$, $EF − FE = H$ (the
corresponding map $ρ$ is given by $ρ(e) = E$, $ρ(f) = F$, $ρ(h) = H$).

Let $V$ be a finite dimensional representation of $\mathfrak{sl}(2)$ (the ground field in this problem is $\C$).

\begin{enumerate}[(a)]
\item Take eigenvalues of $H$ and pick one with the biggest real part. Call it $λ$. Let $\overline{V} (λ)$ be the
generalized eigenspace corresponding to $λ$. Show that $E|_{\overline{V} (λ)} = 0$.
\item Let $W$ be any representation of $\mathfrak{sl}(2)$ and $w ∈ W$ be a nonzero vector such that $Ew = 0$.
For any $k > 0$ find a polynomial $P_k(x)$ of degree $k$ such that $E^kF^kw = P_k(H)w$. (First compute
$EF^kw$, then use induction in $k$).
\item Let $v ∈  \overline{V} (λ)$ be a generalized eigenvector of $H$ with eigenvalue $λ$. Show that there exists
$N > 0$ such that $F^Nv = 0$.
\item Show that $H$ is diagonalizable on $ \overline{V} (λ)$. (Take $N$ to be such that $F^N = 0$ on $\overline{V} (λ)$, and
compute $E^NF^Nv$, $v ∈ \overline{ V} (λ)$, by (b). Use the fact that $P^k(x)$ does not have multiple roots).
\item Let $N_v$ be the smallest $N$ satisfying (c). Show that $λ = N_v − 1$.
\item Show that for each $N > 0$, there exists a unique up to isomorphism irreducible representation
of $\mathfrak{sl}(2)$ of dimension $N$. Compute the matrices $E$, $F$, $H$ in this representation using a convenient
basis. (For $V$ finite dimensional irreducible take $λ$ as in (a) and $v ∈ V (λ)$ an eigenvector of $H$.
Show that $v, Fv, \dots, F^λv$ is a basis of $V$, and compute the matrices of the operators $E$, $F$, $H$ in this
basis.)

\item[] Denote the $λ + 1$-dimensional irreducible representation from (f) by $V_λ$. Below you will show
that any finite dimensional representation is a direct sum of $V_λ$.
\item Show that the operator $C = EF + FE + H^2/2$ (the so-called Casimir operator) commutes
with $E$, $F$, $H$ and equals $\frac{λ(λ+2)}{2} Id$ on $V_λ$.

\item[] Now it will be easy to prove the direct sum decomposition. Namely, assume the contrary, and
let $V$ be a reducible representation of the smallest dimension, which is not a direct sum of smaller
representations.

\item Show that $C$ has only one eigenvalue on $V$, namely $\frac{λ(λ+2)}{2}$ for some nonnegative integer $λ$
(use that the generalized eigenspace decomposition of $C$ must be a decomposition of representations).
\item Show that $V$ has a subrepresentation $W = V_λ$ such that $V/W = nV_λ$ for some $n$ (use (h)
and the fact that $V$ is the smallest which cannot be decomposed).
\item Deduce from (i) that the eigenspace $V(λ)$ of $H$ is $n + 1$-dimensional. If $v_1, \dots, v_{n+1}$ is its
basis, show that $F^jv_i$, $1 ≤ i ≤ n+1$, $0 ≤ j ≤ λ$ are linearly independent and therefore form a basis
of $V$ (establish that if $Fx = 0$ and $Hx = μx$ then $Cx = \frac{μ(μ−2)}{2}x$ and hence $μ = −λ$).
\item Define $W_i = \gene{v_i, Fv_i, \dots, F^λv_i}$. Show that $V_i$ are subrepresentations of $V$ and derive a
contradiction with the fact that $V$ cannot be decomposed.
\end{enumerate}
\end{ejercicio}
\begin{solucion}\
\begin{enumerate}[(a)]
\item Sea $\lambda$ el autovalor de $H$ con mayor parte real y sea $v$ un autovector generalizado asociado. De la ecuación $HE-EH=2E$ obtenemos 
\[
(H - (\lambda + 2)I)(Ev) = E(H - (\lambda + 2)I)v + 2Ev = E(H - \lambda I)v
\]
Esto implica que 
\[
(H - (\lambda + 2)I)^n (Ev) = E(H - \lambda I)^n v=0
\]
por lo que $Ev$ es un autovector generalizado de $H$ para el autovalor $\lambda+2$, pero como $\lambda$ era el de mayor parte real, se tiene necesariamente que $Ev=0$. 

\item Source \url{http://brianbi.ca/etingof/}

Primero probamos que $[H,F^k]=-2kF^k$ por inducción. Para $k=1$ se tiene por las relaciones del álgebra. Para $k>1$ basta usar que el corchete es una derivación en la segunda coordenada, es decir, $[A,BC]=[A,B]C+B[A,C]$ (por la identidad de Jacobi). Tomando $A=H$, $B=F^{k-1}$ y $C=F$, se deduce el resultado con la hipótesis de inducción. 

Ahora por inducción también, $[E,F^k]=kF^{k-1}H-k(k-1)F^{k-1}$. Para $k=1$ es evidente por las relaciones del álgebra. Para $k\geq 1$ tenemos lo siguiente:

\begin{align*}
[E,F^k]&=F[E,F^{k-1}]+[E,F]F^{k-1}\\
&=F((k-1)F^{k-2}H-(k-1)(k-2)F^{k-2})+HF^{k-1}\\
&=(k-1)F^{k-1}H-(k-1)(k-2)F^{k-1}+F{k-1}H+[H,F^{k-1}]\\
&=kF^{k-1}H-(k-1)(k-2)F^{k-1}-2(k1)F^{k-1}\\
&=kF^{k-1}H-k(k-1)F^{k-1}
\end{align*}

Probamos como último resultado previo que $EH^kw=0$ para $k\geq 0$. Es suficiente usar que $EH^k=(HE+[E,H])H^{k-1}$ e inducción. Es inmediato a partir de esto que $EP(H)w=0$ para cualquier polinomio $P$. 

Sea entonces $P$ un polinomio arbitrario. Tenemos
\begin{align*}
E^kF^kP(H)w&=E^{k-1}(EF^k)P(H)w\\
&=E^{k-1}(F^kE+[E,F^k])P(H)w\\
&=E^{k-1}(kF^{k-1}H-k(k-1)F^{k-1})P(H)w\\
&=E^{k-1}F^{k-1}(H-(k-1))P(H)w.
\end{align*}

Por tanto
\[
E^kF^kw=k!H(H-1)(H-2)\cdots (H-(k-1))w
\]

\item Observemos que, en general
\[
(H - (\lambda - 2k)I)(F^k v) = F^k(H - \lambda I)v
\]
Iterando la primera parte del razonamiento del apartado (a), obtendríamos que $\lambda-2k$ es autovalor $\forall k \in \Z^+$, pero dado que $V$ es de dimensión finita, ha de existir $N$ tal que $\lambda -2N$ no sea autovalor, pero $\lambda - 2(N-1)$ sí. Razonando como en dicho apartado
$$
(H-(\lambda - 2N)I)^n(F^Nv) = F^N (H-\lambda I)^nv = 0 
$$
Lo cuál implica necesariamente que $F^N v= 0$.
\item Sea $v\in\overline{V}(\lambda)$, tenemos por (b) y (c)	 que $0=E^NF^Nv=N! H(H-1)\cdots (H-(N-1))v$, luego $$H(H-1)\cdots (H-(N-1))v=0$$
para todo $v\in\overline{V}(\lambda)$. Entonces tenemos que, o bien $(H-(N-1))v=0$ (en cuyo caso $\lambda=N-1$) o bien $(H-(N-1))v$ es un autovector con autovalor $\lambda$, e inductivamente llegamos a que necesariamente $\lambda\in\{0,1,\dots, N-1\}$. Dado que los polinomios en $H$ conmutan, podemos reescribir el anterior de la siguiente manera
\[
0 = \left(\prod_{0 \leq i < N, i \neq \lambda} H-i\right) (H-\lambda)v
\]
Como ninguno de los $i$ es igual a $\lambda$, $(H-\lambda)v$ no puede ser un autovector generalizado con autovalor $\lambda$ (contrarrecíproco del razonamiento anterior), por lo que $(H-\lambda)v=0$ y $v$ es un autovector ordinario. Como esto ocurre para todo $v\in\overline{V}(\lambda)$ se tiene que $H$ es diagonalizable en $\overline{V}(\lambda)$. 

\item Es inmediato a partir del razonamiento anterior, aplicado a $P_k(H)v$, pues solo puede ser considerado a partir de $k=N_v$.

\item Sea $V$ de dimensión finita e irreducible. Por el apartado anterior, tenemos que los autovalores de $H$ son reales y el mayor de ellos es $\lambda=N-1$ para el $N$ de los apartados anteriores. Sea $v\in V(N-1)$ un autovector. Como $F^Nv=0$ pero $F^{N-1}v\neq 0$, es es un sencillo ejercicio de álgebra lineal comprobar que son linealmente independientes, simplemente basta aplicar a una combinación lineal $\alpha_0v+\alpha_1Fv+\cdots \alpha_{N-1}F^{N-1}v=0$ el homomorfismo $F^{N-1}$ para concluir que $\alpha_0=0$, después aplicar $F^{N-2}$ y así sucesivamente. Ahora, el subespacio $\gene{v, Fv,\dots, F^{N-1}v}$ es claramente invariante por $F$ y también por $H$ usando directamente la relación $HF-FH=-2F$. Ahora, por el cálculo que hicimos anteriormente en (b) de $[E,F^k]$ tenemos para todo $k>0$
\[
EF^k v = F^k Ev + kF^{k-1}Hv -k(k-1)F^{k-1}v = k(\lambda-k+1) F^{k-1}v
\]
por lo que el subespacio también es invariante por $E$. Como $V$ es irreducible, necesariamente $V=\gene{v, Fv,\dots, F^{N-1}v}$. 
\begin{itemize}
\item Claramente la matriz de $F$ tiene $1$ en la subdiagonal y es $0$ en el resto.
\item Por el razonamiento que hicimos en (c) los autovalores de $H$ asociados a los vectores $F^kv$ son precisamente $\lambda-2k$ $\forall k =0,\dotsc,\lambda$ (o $N - (2k+1)$ $\forall k=0,\dotsc,\lambda$). Por tanto, la acción de $H$ es precisamente la matriz diagonal cuya componente $kk$-ésima es $N-(2k-1)$ $\forall k=1,\dotsc,\lambda+1$.
\item Por el razonamiento que hicimos en (c) los autovalores de $H$ asociados a los vectores $F^kv$ son precisamente $\lambda-2k$ $\forall k =0,\dotsc,\lambda$ (o $N - (2k+1)$ $\forall k=0,\dotsc,\lambda$). Por tanto, la acción de $H$ es precisamente la matriz diagonal cuya componente $k$-ésima es $N-(2k-1)$ $\forall k=1,\dotsc,\lambda+1$.
\item Resolviendo $EF-FE =H$ podemos obtener la matriz de $E$. 
\end{itemize}
Finalmente, tenemos que probar que $V_\lambda$ es irreducible. Sea $w\in V_\lambda$ no nulo. Entonces $w=\sum_i c_iF^iv$. Sea $m$ el primer entero tal que $c_m$ es no nulo, entonces si multiplicamos por $F^{\lambda-m}$ obtenemos $F^{\lambda-m}w = c_m F^\lambda v$. Como hemos visto arriba, aplicando $E$ obtenemos todos los vectores de la base, luego cualquier subespacio cerrado para las acciones del álgebra tiene que ser el total.
\item Los papeles de $E$ y $F$ son intercambiables, por lo que calculamos los conmutadores $[E,C]$ y $[H,C]$. 
\begin{align*}
[E,C]&=[E, EF + FE + H^2/2]=[E,EF]+[E,FE]+[E,H^2]/2=\\
&=[E,E]F+E[E,F]+[E,F]E+F[E,E]+[E,H]H/2+H[E,H]/2=\\
&=E[E,F]+[E,F]E+[E,H]H/2+H[E,H]/2=\\
&=EH+HE-EH-EH=0
\end{align*}
\begin{align*}
[H,C]&=[H, EF + FE + H^2/2]=[H,EF]+[H,FE]+[H,H^2]/2=\\
&=[H,E]F+E[H,F]+[H,F]E+F[H,E]+[H,H]H/2+H[H,H]/2=\\
&=2EF-2EF-2FE+2FE=0
\end{align*}
Por lo que efectivamente conmutan. Dado que $V_\lambda$ es irreducible y $C$ está en su centro, actúa como la multiplicación por un escalar. por el Problema 1.21 Sea ahora $v\in V(\lambda)\subset V_\lambda$, tenemos que $Ev=0$. Usando la identidad $FE-EF=H$ obtenemos
\[
Cv=EFv+FEv+H^2v/2=EFv+\lambda^2v/2=Hv+FEv+\lambda^2v/2=\lambda+\lambda^2v/2=\frac{\lambda(\lambda+2)}{2}v
\]

\item En el apartado anterior hemos probado que $C$ es central. Por ser $V$ indecomponible, podemos aplicar el Ejercicio \ref{ejer:1.21}(b), por lo que $C$ actúa mediante la multiplicación por un escalar determinado por alguna representación irreducible de $V$. Como en $V_\lambda$, que es irreducible, actúa multiplicando por $\frac{\lambda(\lambda+2)}{2}$, este es su único autovalor en $V$. 
\item Dado que $V$ es de dimensión finita, cualquier subrepresentación suya, así como el cocieciente, serán de dimensión finita (y menor estrictamente que la de $V$). Si $V/W$ es irreducible, dado que es una representación de $\mathfrak{sl}(2)$, tenemos por el apartado (f), necesariamente ha de ser isomorfo a $V_\lambda$, por lo que $n=1$ en este caso. Si $V/W$ es reducible, como $V$ era el de menor dimensión idecomponible, $V/W$ debe poder escribirse como suma directa de subrepresentaciones. Estas a su vez, usando un argumento recursivo y dado que $\dim(V)$ es finito, podemos suponer que son irreducibles y, por tanto, son isomorfas a $V_\lambda$.
\item Supongamos que $V(\lambda)$ es $m$-dimensional. Dado que $W(\lambda)$ tiene dimensión $1$, $V/W(\lambda)$ tiene dimensión $m-1$. Como $V/W = nV_\lambda$, se sigue que $m-1 = n$ y, por tanto, $m=n+1$.

Sea $\{v_1,\dotsc,v_{n+1}\}$ una base de $V(\lambda)$. Por el apartado (e) sabemos que para cada $j\in \{0,\dotsc,\lambda\}$ los vectores $S_j = \{F^jv_1,\dotsc,F^jv_{n+1}\}$ son no nulos.Además, $S_j$ son autovectores de $H$ asociados al autovalor $\lambda-2j$. Por (b) sabemos que $\gene{E^jS_j}$ es $n+1$ dimensional, pues $E^jF^jv_i$ es proporcional a $v_i$, luego $\gene{S_j}$ es $n+1$ dimensional. Dado que autovectores asociados a diferentes autovalores son independientes, tenemos que $|S|=\sum_{j}|S_j| = (n+1)(\lambda+1)=\dim V$. Por tanto, $S$ es una base de $V$. 
\item Es inmediato teniendo en cuenta que, por los argumento que vimos en (f), $W_i$ es necesariamente invariante mediante $E,F$ y $H$. Además, por el razonamiento de (j) es claro que están en suma directa. Por tanto, tenemos una contradicción.
\end{enumerate}
\end{solucion}

\newpage

\begin{ejercicio}{de la 2.3}
Let $A_1$, $A_2$, $\dots$, $A_n$ be $n$ algebras with units $1_1$, $1_2$, $\dots$, $1_n$, respectively. Let $A = A_1\oplus A_2\oplus\cdots\oplus A_n$.
Clearly, $1_i1_j = δ_{ij}1_i$, and the unit of $A$ is $1 = 1_1 + 1_2 + \cdots + 1_n$.

For every representation $V$ of $A$, it is easy to see that $1_iV$ is a representation of $A_i$ for every
$i ∈ \{1, 2, \dots, n\}$. Conversely, if $V_1, V_2, \dots, V_n$ are representations of $A_1, A_2, \dots, A_n$, respectively,
then $V_1 ⊕ V_2 ⊕ \cdots ⊕ V_n$ canonically becomes a representation of $A$ (with $(a_1, a_2, \dots, a_n) ∈ A$ acting
on $V_1 ⊕ V_2 ⊕ \cdots ⊕ V_n$ as $(v_1, v_2, \dots, v_n) → (a_1v_1, a_2v_2, \dots, a_nv_n)$).

\begin{enumerate}[(a)]
\item Show that a representation $V$ of $A$ is irreducible if and only if $1_iV$ is an irreducible representation
of $A_i$ for exactly one $i ∈ \{1, 2, \dots, n\}$, while $1_iV = 0$ for all the other $i$. Thus, classify the
irreducible representations of $A$ in terms of those of $A_1, A_2, \dots, A_n$.
\item Let $d ∈ \N$. Show that the only irreducible representation of $Mat_d(k)$ is $k^d$, and every finite
dimensional representation of $Mat_d(k)$ is a direct sum of copies of $k^d$.

Hint: For every $(i, j) ∈ \{1, 2, \dots, d\}^2$, let $E_{ij} ∈ Mat_d(k)$ be the matrix with $1$ in the $i$th row of the
$j$th column and $0$’s everywhere else. Let $V$ be a finite dimensional representation of $Mat_d(k)$. Show
that $V = E_{11}V ⊕ E_{22}V ⊕ \dots ⊕ E_{dd}V $, and that $\phi_i : E_{11}V → E_{ii}V$ , $v → E_{i1}v$ is an isomorphism for
every $i ∈ \{1, 2, \dots, d\}$. For every $v ∈ E_{11}V $, denote $S (v) = \gene{E_{11}v,E_{21}v, \dots,E_{d1}v}$. Prove that $S (v)$
is a subrepresentation of $V$ isomorphic to $k^d$ (as a representation of $Mat_d(k)$), and that $v ∈ S (v)$.
Conclude that $V = S (v_1) ⊕ S (v_2) ⊕ \dots ⊕ S (v_k)$, where $\{v_1, v_2, \dots, v_k\}$ is a basis of $E_{11}V$.

\item Conclude Theorem 2.6. 
\end{enumerate}
\end{ejercicio}
\begin{solucion}\
\begin{enumerate}[(a)]
\item Sea $V$ una representación irreducible de $A$. Tengamos en cuenta que $1_i V = 0$ no puede ser cierto para todo $i$, pues entonces $(1_1+ \cdots 1_n)V =0$, lo cuál es absurdo, pues dicha suma es precisamente $1$. Sea $i$ tal que $1_i V \neq 0$ y sea $v\in 1_iV$. Por ser $V$ irreducible, el Ejercicio \ref{25} nos dice que cualquier vector no nulo de $V$ es cíclico. Por tanto, para todo $w\in V$ existe $a=(a_1,\dots, a_i,\dots, a_n)$ tal que $w=av_i=\sum_j a_jv_i$. Por tanto, 
\[
1_iw=\sum_j 1_ia_jv_i=1_ia_iv_i=a_iv_i
\]
de donde deducimos que todo vector de $1_iV$ es cíclico visto como representación de $A_i$, por lo que $1_iV$ es irreducible. 

Si además de $1_iV$ existiera un $1_jV\neq 0$, tendríamos entonces que cada uno de ellos sería una subrepresentación, y además es claro que deben ser distintas, por lo que $V$ no sería irreducible. El recíproco es trivial. Tenemos entonces que cada representación irreducible $V_i$ de $A_i$ nos da una representación irreducible de $A$, eligiendo $V_i\neq 0$ y la acción $(a_1,\dots, a_i,\dots, a_n)v=a_iv$. 

\item Como $\sum_i E_{ii}=Id$, cualquier $v\in V$ se escribe como $v=\sum_i E_{ii}v$, por lo que $V=\oplus_i E_{ii}$. Ahora, dado $v\in E_{11}V$, tenemos que $v=E_{11}w$, y por tanto $E_{i1}v=E_{i1}E_{11}w=E_{i1}w=E_{ii}E_{i1}w$, luego podemos definir $\phi_i:E_{11}V\to E_{ii}V$ como $\phi_i(v)=E_{i1}v$. Probamos que $\phi_i$ es isomorfismo. Dado  $w\in E_{ii}V$, buscamos $v\in E_{11}V$ tal que $E_{i1}v=w$. Como $E_{1i}E_{i1}=E_{11}$ y $E_{11}v=v$ por ser $E_{11}^2=E_{11}$, tenemos que $v=E_{1i}w$, luego hay exactamente un $v$ para cada $w$, que es lo que queríamos probar. 

Como hemos comentado para $v\in E_{11}v$, $E_{11}v=v$, por lo que claramente $v\in S(v)$. Suponemos ahora que $v\neq 0$, porque en caso contrario el resultado es falso. Es claro que $S(v)$ es una subrepresentación de $V$, ya que para cualquier matriz $M\in Mat_d(k)$, $ME_{i1}$ es una matriz que solo puede tener entradas no nulas en la primera columna, luego es una combinación lineal de las matrices que generan $S(v)$. Por otra parte, ninguno de los $E_{i1}v$ se anula por ser $\phi_i$ inyectiva. Además, estos vectores son linealmente independientes por el isomorfismo $V=\oplus_iE_{ii}$, ya que cada $E_{i1}v$ está en un $E_{ii}V$. Tenemos entonces un isomorfismo de espacios vectoriales canónico $S(v)\to k^d$ dado por $E_{i1}v\mapsto e_i$. Tenemos que comprobar que este isomorfismo lo es también de representaciones. Basta comprobar la conmutatividad del diagrama
\[
\begin{tikzcd}
S(v)\arrow[r]\arrow[d, "M"] & k^d\arrow[d, "M"]\\
S(v)\arrow[r] & k^d
\end{tikzcd}
\]
para los elementos $E_{i1}v$ de la base de $S(v)$. Para ello observemos que recorriendo el diagrama en sentido horario obtenemos $Me_iv=M_{\cdot i}v$, donde $M_{\cdot i}$ representa la $i$-ésima columna de $M$. En sentido contrario tenemos $ME_{i1}v=M_{\cdot i}v$, luego efectivamente el diagrama conmuta. 

Por último, sea $\{v_1,\dots, v_k\}$ una base de $E_{11}V$. Tenemos mediante los $\phi_i$ y el isomorfismo $V=\oplus_iE_{ii}V$ que $V=\oplus_i E_{11}V$. Ahora, $\oplus_i\phi_i:\oplus_i E_{11}\to \oplus_i E_{ii}$ lleva en cada componente la base $\{v_1,\dots, v_k\}$ a una base $\{E_{i1}v_1,\dots, E_{i1}v_k\}$, luego podemos extraer para cada $1\leq j\leq k$ la base de $S(v_j)$ cogiendo un elemento de cada uno de estos conjuntos. Como además esta elección es exhaustiva, tenemos que $V=S(v_1)\oplus\cdots\oplus S(v_k)$. Es fácil ver que además $S(v_j)$ es irreducible. 

En definitiva, las representaciones finito-dimensionales de $Mat_d(k)$ es isomorfa a una suma de copias de $k^d$ y además cada una de estas copias es irreducible, por lo que una representación $V$ es irreducible si y solo si $V\cong k^d$. 

\item Por el apartado (a), toda representación irreducible de $A=\oplus_i Mat_{d_i}(k)$ se obtiene a partir de cada representación irreducible de $Mat_{d_i}(k)$ y por (b) son precisamente $k^{d_i}$ y cualquier representación de dimensión finita de $A$ es suma directa de ellas. 
\end{enumerate}
\end{solucion}
\newpage
\begin{ejercicio}{2.25 (The Clifford Algebra)}
Let $V$ be a finite dimensional complex vector space
equipped with a symmetric bilinear form $(, )$. The Clifford algebra $Cl(V )$ is the quotient of the
tensor algebra $TV$ by the ideal generated by the elements $v ⊗ v −(v, v)1$, $v ∈ V$ . More explicitly, if
$x_i$, $1 ≤ i ≤ N$ is a basis of $V$ and $(x_i, x_j) = a_{ij}$ then $Cl(V )$ is generated by $x_i$ with defining relations
$$x_ix_j + x_jx_i = 2a_{ij} ,\ x^2_i = a_{ii}.$$
Thus, if $(, ) = 0$, $Cl(V ) = ∧V $.

\begin{enumerate}[(i)]
\item Show that if $(, )$ is nondegenerate then $Cl(V )$ is semisimple, and has one irreducible representation
of dimension $2^n$ if $\dim V = 2n$ (so in this case $Cl(V )$ is a matrix algebra), and two such
representations if $\dim(V ) = 2n+1$ (i.e., in this case $Cl(V )$ is a direct sum of two matrix algebras).

Hint. In the even case, pick a basis $a_1, \dots, a_n, b_1,\dots , b_n$ of $V$ in which $(a_i, a_j) = (b_i, b_j) = 0$,
$(a_i, b_j) = δ_{ij}/2$, and construct a representation of $Cl(V )$ on $S := ∧(a_1, \dots, a_n)$ in which $b_i$ acts as
“differentiation” with respect to $a_i$. Show that $S$ is irreducible. In the odd case the situation is
similar, except there should be an additional basis vector $c$ such that $(c, a_i) = (c, b_i) = 0$, $(c, c) =
1$, and the action of $c$ on $S$ may be defined either by $(−1)^{degree}$ or by $(−1)^{degree+1}$, giving two
representations $S^+$, $S^−$ (why are they non-isomorphic?). Show that there is no other irreducible
representations by finding a spanning set of $Cl(V )$ with $2^{\dim V}$ elements.

\item Show that $Cl(V )$ is semisimple if and only if $(, )$ is nondegenerate. If $(, )$ is degenerate, what
is $Cl(V )/Rad(Cl(V ))$?
\end{enumerate}
\end{ejercicio}
\begin{solucion}
\end{solucion}\
\begin{enumerate}
\item Supongamos que $\dim V=2n$. Como $(,)$ es bilinear y no degenerada, se puede aplicar el método de Gram-Schmidt (modificado) para conseguir una base $\{a_1,\dots, a_n,b_1,\dots, b_n\}$ para la cual $(a_i,a_j)=(b_i,b_j)=0$ y $(a_i,b_j)=\delta_{ij}/2$. Sea $S=\land (a_1,\dots, a_n)$ y definimos la siguiente acción de $Cl(V)$ en $S$. Para $w\in S$, $\rho(a_i)(w)=a_i\land w$ y $\rho(b_i)(w)=d_{a_i}w=\frac{dw}{da_i}$. La derivación con respecto a $a_i$ de un producto $w_1\land w_2$ donde $w_1$ es de grado $p$ (es una $p$-forma) se define recursivamente por la regla de Leibniz, $d(w_1\land w_2)=dw_1\land w_2+(-1)^pw_1\land w_2$. Tenemos que comprobar que esta acción verifica las relaciones de $Cl(V)$ para que esté bien definida.

\begin{align*}
\rho(a_i a_j + a_j a_i - 2( a_i, a_j))(w)
&= \rho(a_i)\rho(a_j)(w) + \rho(a_j)\rho(a_i)(w) \\
&= a_i \wedge a_j \wedge w + a_j \wedge a_i \wedge w \\
&= (a_i \wedge a_j + a_j \wedge a_i) \wedge w \\
&=0
\end{align*}

\begin{align*}
\rho(a_i b_j + b_j a_i - 2( a_i, b_j))(w)
&= a_i \wedge d_{a_j}w + d_{a_j}(a_i \wedge w) -
\delta_{ij}w \\
&= a_i \wedge d_{a_j}w\omega + (d_{a_j}a_i) \wedge w -
a_i \wedge d_{a_j}w - \delta_{ij}w\\
&= \delta_{ij}w - \delta_{ij}w \\
&= 0
\end{align*}

\begin{align*}
\rho(b_i b_j + b_j b_i - 2( b_i, b_j))(w)
&= \rho(b_i)\rho(b_j)(w) + \rho(b_j)\rho(b_i)(w) \\
&= d_{a_i} d_{a_j}w + d_{a_j} d_{a_i}w 
\end{align*}
Probamos ahora que $d_{a_i} d_{a_j}w + d_{a_j} d_{a_i}w=0$ para toda $p$-forma $w$. Para $p\leq 1$ es trivial. Sea entonces $w$ una $p$-forma para $p\geq 2$, de modo que podemos escribir $w=a_k\land w_k$, con $w_k$ una $(p-1)$-forma. Entonces
\begin{align*}
d_{a_i}d_{a_j}a_k\land w_k+d_{a_j}d_{a_i}a_k\land w_k&=d_{a_i}(\delta_{jk}\land w_k-a_k\land d_{a_j}w_k)+d_{a_j}(\delta_{ik}\land w_k-a_k\land d_{a_i}w_k)\\
&=\delta_{jk} d_{a_i}w_k-\delta_{ik} d_{a_j}w_k+\delta_{ik}d_{a_j}w_k-\delta_{jk}d_{a_i}w_k\\
&=0
\end{align*}
Lo que prueba que la acción está bien definida.

Probamos ahora que esta representación es irreducible. Sea $w=ca_{i_1}\land\cdots\land a_{i_p}$ una $p$-forma ($c\in\C^*$). Entonces es claro que $\rho(b_{i_p}\cdots b_{i_1})(c^{-1}w)=1$. Como 1 es obviamente cíclico, todo elemento no nulo de $S$ es cíclico, lo cual implica que $S$ es irreducible por el ejercicio \ref{ejer:1.25}. Por el ejercicio \ref{ejer:1.34}(c) tenemos que $\dim S=2^n$. Como además $Cl(V)$ está generado por el mismo tipo de monomios que $S$ pero con base de tamaño $2n$, $\dim Cl(V)\leq 2^{2^n}$. Del teorema 2.12 deducimos que $$\dim Cl(V)-\dim Rad(Cl(V))=\sum_i\dim V_i$$ donde $V_i$ son las representacioens irreducibles de $Cl(V)$. Hemos encontrado una representación de dimensión $2^n$, pero podemos encontrarlas de dimensión $2^i$ para  $0\leq i\leq n$ haciendo que algunas parejas $a_i,a_j$ (y por tanto $b_i,b_j$) induzcan la misma acción. Esto además se puede hacer de tantas formas como parejas haya, por lo que obtenemos $\sum_i\dim V_i\geq 2^{2^n}$, puesto que $\sum_{i=0}^n2^i\geq 2^n$. Entonces, $$\dim Cl(V)-\dim Rad(Cl(V))\geq 2^{2^n},$$ pero $\dim Cl(V)\leq 2^{2^n}$, lo cual implica que necesariamente se da la igualdad y $Rad(Cl(V))$, con lo que concluimos que $Cl(V)$ es semisimple.\\

Vamos ahora al caso de que $\dim V=2n+1$. Tomamos ahora una base como la de dimensión par añadiendo un vector $c$ cumpliendo $(a_i,c)=(b_i,c)=0$ y $(c,c)=1$. Definimos ahora dos acciones $\rho_+,\rho_-$ iguales a $\rho$ del anterior caso sobre los $a_i$ y $b_i$, pero $\rho_+(c)(w)=(-1)^p$ y $\rho_-(c)(w)=(-1)^{p+1}$ para una $p$-forma $w\in S$. Denotamos $S_+$ a la representación inducida por $\rho_+$ y $S_-$ a la representación inducida por $\rho_-$. Igual que antes, tenemos que comprobar que estas acciones están bien definidas, para lo cual solo tenemos que verificar las relaciones en las que interviene $c$, y lo haremos solo en $\rho_+$ porque para la otra es análoga.

\begin{align*}
\rho_+(c^2 - ( c, c))(w)
&= \rho_+(c)(\rho_+(c)(w)) - w \\
&= (-1)^p(-1)^p w - w \\
&= 0
\end{align*}
\begin{align*}
\rho_+(a_i c + c a_i - ( a_i, c ))(w)
&= \rho_+(a_i)(\rho_+(c)(w)) + \rho_+(c)(\rho_+(a_i)(w)) \\
&= a_i \wedge ((-1)^p w) + (-1)^{p+1}(a_i \wedge w) \\
&= (-1)^p a_i \wedge w + (-1)^{p+1}a_i \wedge w \\
&= 0
\end{align*}
\begin{align*}
\rho_+(b_i c + c b_i - ( b_i, c ))(w)
&= \rho_+(b_i)(\rho_+(c)(w)) + \rho_+(c)(\rho_+(b_i)(w)) \\
&= d_{a_i}((-1)^p \omega) + (-1)^{p-1}(d_{a_i}w) \\
&= (-1)^pd_{a_i}w + (-1)^{p-1}d_{a_i}w \\
&= 0
\end{align*}
Con esto ya tenemos que las representaciones están bien definidas. La prueba de que $S_+$ y $S_-$ son irreducibles es igual que la de $S$ del caso anterior. Es fácil comprobar que estas representaciones no son isomorfas. Si existiera un isomorfismo de representaciones $f:S_+\to S_-$, $f$ debe llevar $p$-formas en $p$-formas, luego para una $p$-forma $w$ deberíamos tener $(-1)^{p+1}f(w)=\rho_-(c)(f(w))=f(\rho_+(c)(w))=(-1)^pf(w)$, lo cual no es posible. Igual que antes, tanto $S_+$ como $S_-$ tienen dimensión $2^n$ y podemos encontrar un sistema generador de $V$ y podemos recurrir a un argumento combinatorio similar al del anterior caso para demostrar que $Cl(V)$ es semisimple. 
\end{enumerate}

\newpage
\begin{ejercicio}{Sec 3.5}
Sea $G$ un grupo finito. Sea $V_i$ la representaciones irreducibles de $\C[G]$. Para cada $i$ 
$$
\psi_i = \frac{\dim V_i}{|G|}\sum_{g\in G}\chi_{V_i}(g)g^{-1}\in \C[G]
$$
\begin{itemize}
\item Probar que $\psi_i$ actúa en $V_j$ como la identidad si $i=j$ y como $0$ en otro caso.
\item Probar que $\psi_i$ es idempotente, es decir, que $\psi_i^2=\psi_i$ para cualquier $i$ y que $\psi_i\psi_j = 0$ si $i\neq j$.
\end{itemize}
\end{ejercicio}
\begin{solucion}
\begin{itemize}
\item[]
\item Notemos que, sea $h\in G$ entonces basta aplicar que recorrer $g \in G$ es equivalente a recorrer $h^{-1}gh\in G$ y que el carácter es multiplicativo, luego tenemos necesariamente
$$
\chi_{V_i}(h^{-1}gh) = \chi_{V_i}(h^{-1})\chi_{V_i}(g)\chi_{V_i}(h)= \chi_{V_i}(h^{-1})\chi_{V_i}(h)\chi_{V_i}(g) = \chi_{V_i}(g)
$$
Por tanto, podemos escribir
\begin{align*}
h \psi_i &=  h \frac{\dim V_i}{|G|}\sum_{g\in G}\chi_{V_i}(g)g^{-1}\\
&= h \frac{\dim V_i}{|G|}\sum_{g\in G}\chi_{V_i}(h^{-1}gh)h^{-1}g^{-1}h\\
&= \frac{\dim V_i}{|G|}\sum_{g\in G}h\chi_{V_i}(g)h^{-1}g^{-1}h\\
&=\frac{\dim V_i}{|G|}\sum_{g\in G}\chi_{V_i}(g)g^{-1} h\\
&=\psi_i h
\end{align*}
Por tanto $\psi_i$ conmuta con $G$ y, por linealidad, con $\C[G]$. Por el Ejercicio 1.21, $\psi_i$ actúa como un escalar en las representaciones irreducibles de $k[G]$ (pues son todas finitas por el Teorema de Maschke). 

Tenemos que probar las constantes de los caracteres son $1$ si $i=j$ y $0$ en caso contrario. Calculemos directamente usando la linealidad del caracter
\begin{align*}
\chi_{V_j}  \phi_i &= \frac{\dim V_i}{|G|}\sum_{g\in G}\chi_{V_i}(g)\chi_{V_j}(g^{-1})\\
& = \frac{\dim V_i}{|G|}\sum_{g\in G}\chi_{V_i}(g)\overline{\chi_{V_j}(g)}
\end{align*}
Por el Teorema 3.8, dado que si $i\neq j$ $V_i \not \cong V_j$, la suma anterior es $0$. Si $tr(\lambda Id) = \lambda \dim(V_j) = 0$, tenemos que $\lambda = 0$. Si $i=j$, entonces la suma es $|G|$, luego el escalar obtenido es $\dim (V_i)$. Por tanto, $tr(\lambda Id) = \lambda \dim(V_i) = \dim(V_i)$ entonces $\lambda = 1$ y actúa como la identidad.
\item Se deduce inmediatamente a partir del apartado anterior. Como $\C[G]$ es semisimple, basta calcular la imagen de $\phi_i^2$ y $\phi_i \phi_j$ en las representaciones irreducibles. 

Sabemos que en $V_i$ $\phi_i^2 = Id^2 = Id = \phi_i$ y en $V_j$ $\phi_i^2 =0^2=0  \phi_i$. Si $i \neq j$, entonces distingamos casos en función de $k$. Si $k\neq i$ y $k\neq j$, $\phi_i$ y $\phi_j$ actúan en $V_k$ como $0$, luego $\phi_i\phi_j =0$. Si $k=i$ (análogo $k=j$), $\phi_i = Id$ y $\phi_j = 0$, luego $\phi_i\phi_j = 0$.	
\end{itemize}
\end{solucion}


\newpage
\begin{ejercicio}{3.17}
Let $G$ be the group of symmetries of a regular $N$-gon (it has $2N$ elements).
\begin{enumerate}[(a)]
\item Describe all irreducible complex representations of this group (consider the cases of odd and even $N$)
\item Let $V$ be the 2-dimensional complex representation of G obtained by complexification of the standard representation on the real plane (the plane of the polygon). Find the decomposition of $V ⊗ V$ in a direct sum of irreducible representations.
\end{enumerate}
\end{ejercicio}
\begin{solucion}

\end{solucion}


\newpage
\begin{ejercicio}{3.19}
Let $V$ be a finite dimensional complex vector space, and $GL(V)$ be the group of invertible linear transformations of $V$. Then $S^nV$ and $\Lambda^m V$ ($m ≤ \dim(V )$) are representations of $GL(V )$ in a natural way. Show that they are irreducible representations.
\end{ejercicio}
\begin{solucion}

\end{solucion}

\end{document}
