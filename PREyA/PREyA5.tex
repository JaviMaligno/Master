\documentclass[PREyA.tex]{subfiles}
\providecommand{\abs}[1]{\left\lvert#1\right\rvert}
\begin{document}

\chapter{Procesos de Poisson}
\section{Introducción}
\begin{theorem}[Teorema Central del Límite de Poisson]
Supongamos la matriz aleatoria triangular de v.a.i. $X_{n,m} \sim Ber(p_{n,m})$ con $m\leq n$. Definimos la sucesión $S_n = \sum_{m=1}^n X_{n,m}$. Sean además $\lambda_n = \sum_{m=1}^n p_{n,m}$ tal que $\lambda_n \to \lambda$ y $\max_{k\leq n}p_{n,k}\to0$. Se tiene entonces que
$$
\lim_{n\to \infty} P[S_n = k] = e^{-\lambda}\frac{\lambda^k}{k!}
$$
\end{theorem}
\begin{coro}
Bajo las condiciones anteriores se tiene que para cualquier conjunto $A$
$$
\abs{P(S_n\in A)-P(Z_n\in A)} \leq \sum_{m=1}^n p_{n,m}^2
$$
con $Z_n \sim Poi(\lambda_n)$.
\end{coro}
\section{Postulados para el Proceso de Poisson}
Consideremos una sucesión de sucesos que ocurre en el tiempo en $[0,\infty)$. Sea $N(a,b]$ el número de suceso que ocurren en $(a,b]$. Cada uno de esos sucesos ocurren en los instantes $a<\tau_i\leq b$. Tenemos los siguientes postulados 
\begin{enumerate}
\item El número de sucesos que ocurren intervalos disjuntos son v.a.i. Esto es, para cualquier natural $n\geq 2$ es instantes cualesquiera $0<t_1<t_2<\dotsc<t_n$ las v.a.
$$
N(0,t_1],\dotsc,N(t_{n-1},t_n]
$$
son independientes.
\item Para cualquier $h>0$ e instante $t$ la distribución de $N(t,t+h]$ depende solo de la longitud $h$ y no de $t$.
\item Existe una constante positiva $\lambda$ tal que 
$$
P[N(t,t+h]\geq 1] = \lambda h + o(h)
$$
con $h\to0$ y $o(h)/h\to 0$. A $\lambda$ se le conoce como intensidad del proceso.
\item La probabilidad de que haya dos o más eventos en un intervalo de longitud $h$ es $o(h)$. Es decir,
$$
P[N(t,t+h]\geq 2] = o(h)
$$
\end{enumerate}
Por el primer postulado sabemos que el numero de sucesos que ocurren intervalos disjuntos son independientes. Por el segundo, sabemos que $N(s,t]=N(0,t-s]$. Por tanto, la ley de probabilidad del proceso será la de $N(0,t]$ que denotaremos por $N(t)$.
\begin{theorem}
Bajo las condiciones anteriores se tiene que
$$
P[N(t)=k]=e^{-\lambda t}\frac{(\lambda t)^k}{k!}
$$
\end{theorem}
\begin{proof}
Dividamos el intervalo $(0,t]$ en $n$ subintervalos de igual longitud $t/n$. Definamos las siguientes variables aleatorias $\xi_{n,i}=1$ si hay al menos un suceso en $((i-1)t/n,it/n]$. Definimos $S_n = \sum_{i=1}^n \xi_{n,i}$ el número de subintervalos que contienen al menos un evento, con $p_{n,i}=P[\xi_{n,i}=1] = \lambda\frac{t}{n}+o(t/n)$. 

Ahora bien, se tiene que
\begin{align*}
\abs{P[S_n=k]-e^{-\mu_n}\mu_n^k / k!}&\leq n\left(\frac{\lambda t}{n}+o(t/n)\right)^2 \\
&=\frac{(\lambda t)^2}{n} + 2\lambda t o(t/n)+ m o(t/n)^2
\end{align*}
donde $\mu_n = \sum_{i=1}^n p_{i,n} = \lambda t + n o(t/n)$ sabiendo que $no(t/n)\to 0$, se obtiene que
$$
P[S_n = k] \to e^{-\lambda t}\frac{(\lambda t)^k}{k!}
$$
Además
$$
P[N(t)\neq S_n] \leq \sum_{i=1}^n P\left[N\left(\frac{(i-1)t}{n},\frac{it}{n}\right]\geq 2 \right] \leq n(t/n)\to 0
$$
Por tanto, tomando $n$ suficientemente grande si tiene que
$$
P[N(t)=k]=e^{-\lambda t}\frac{(\lambda t)^k}{k!}
$$
Al proceso estocástico $N(a,b]$ se le llama proceso de Poisson.
\end{proof}
\newpage
\begin{prop}
El proceso de Poisson $\{N(t)\}_{t\geq 0}$ satisface
\begin{itemize}
\item Es un proceso de Markov
\item Tiene incrementos independientes
\item Tiene incrementos estacionarios
\item Para cualesquiera $s\leq t$ y naturales $i\leq j$ las probabilidades de transición son
$$
P[N(t+s)=j\mid N(s)=i] = e^{-\lambda t}\frac{(\lambda t)^{j-i}}{(j-i)!}
$$
\end{itemize}
\end{prop}
\begin{example}
Demostrar que los tiempos de llegadas en un proceso de Poisson son independientes y exponenciales de tasa $\lambda$. 
$$
P[T_1 > t] =  P[N(t) = 0] = e^{-\lambda t}
$$
$$
P[T_2 > t\mid T_1 = s] =  P[N(s,s+t) = 0\mid X_1 = s] = e^{-\lambda t}
$$
Directamente, sean $s_1<\dotsc<s_n<t$. Dado que los intervalos $(0,s_i]$ y $(s_n,t]$ son disjuntos para todo $i$, lo que ocurre en ellos son sucesos independientes, luego
\begin{align*}
P[T_{n+1} > t \mid T_1 = s_1,\dotsc, T_n = s_n] &= P[N(s_n,s_n+t)=0 \mid T_1 = s_1,\dotsc, T_n = s_n]\\
& = P[N(s_n,s_n+t] = 0]\\
&= e^{-\lambda t}
\end{align*}
\end{example}
\begin{example}
Demostrar que la suma de dos procesos de Poisson independentes también es un proceso de Poisson, y determinar su intensidad. Sea $N_i(t)\sim PPoi(\lambda_i t)$. Sea $N(t)=N_1(t)+N_2(t)$

\begin{align*}
P[N(t)= k] &= \sum_{i=0}^k P[N_1(t)=k-i,N_2=i] \\
&= \sum_{i=0}^k e^{-\lambda_1 t}\frac{(\lambda_1 t)^{k-i}}{(k-i)!}e^{-\lambda_2 t}\frac{(\lambda_2 t)^{i}}{i!}\\
&= e^{-(\lambda_1+\lambda_2)t}\frac{((\lambda_1+\lambda_2)t)^k}{k!}
\end{align*}
Por tanto, es un proceso de Poisson con intensidad suma de las intensidades.
\end{example}
\section{Distribuciones asociadas al Proceso de Poisson}
\begin{prop}
Sea $N(t)$ un proceso de Poisson de parámetro $\lambda >0$ para $0<u<t$ y $0\leq  k \leq n$, se tiene que
$$
P[N(u)=k\mid N(t)=n] = \frac{n!}{k!(n-k)!}(u/t)^k(1-u/t)^{n-k}
$$
\end{prop}
\begin{proof}
Sabemos que
\begin{align*}
P[N(u)=k, N(t)=n] = P[N(u)=k, N(t)-N(u)=n-k] = P[N(u)=k]P[N(t)-N(u) = n-k]
\end{align*}
Por tanto
\begin{align*}
P[N(u)=k\mid N(t)=n] &= \frac{P[N(u)=k, N(t)=n]}{P[N(t)=n]}\\
&= \frac{P[N(u)=k]P[N(t)-N(u) = n-k]}{P[N(t)=n]}\\
&= \frac{e^{-\lambda u}(\lambda u)^k/k! e^{-\lambda(t-u)}[\lambda(t-u)]^{n-k}/(n-k)! }{e^{-\lambda t}(\lambda t)^n/n!}\\
&= \frac{n!}{k!(n-k)!}\frac{u^k(t-u)^{n-k}}{t^n}\\
&= \frac{n!}{k!(n-k)!}(u/t)^k(1-u/t)^{n-k}
\end{align*}

\end{proof}

\begin{prop}
Dado el suceso $N(t)=n$, el vector de tiempos $(T_1,\dotsc,T_n)$ tiene la misma distribución que el vector de estadísticos de orden $(Y_{(1)},\dotsc,Y_{(n)})$ de una nuestra aleatoria $Y_1,\dotsc,Y_n$ de una uniforme en $[0,t]$.
$$
f_{T_1,\dotsc,T_n\mid N(t)}(t_1,\dotsc,t_n;n) = \frac{n!}{t^n} \quad 0<t_1<\dotsc<t_n < t
$$
\end{prop}
\begin{proof}
Veamos el caso $n=2$.
\begin{align*}
P[T_1\leq t_1,T_2 \leq t_2 \mid N(t)=2] & = P[N(t_1) \geq 1, N(t_2)\geq 2 \mid N(t)=2]\\
&= \frac{ P[N(t_1) \geq 1, N(t_2)\geq 2, N(t)=2]}{P[N(t)=2]}\\
&= \frac{P[N(t_1)=1,N(t_2)-N(t_1) =1, N(t)-N(t_2)=0]}{P[N(t)=2]}\\
&= \frac{e^{-\lambda t_1}\lambda t_1 e^{-\lambda(t_2-t_1)}\lambda(t_2-t_1) e^{-\lambda(t-t_2)}}{e^{-\lambda t}(\lambda t)^2/2!}\\
&= \frac{2!t_1(t_2-t_1)}{t^2}
\end{align*}
Derivando con respecto a $t_1$ y $t_2$ obtenemos 
\begin{align*}
f_{T_1,T_2\mid N(2)}(t_1,t_2;2) &= \frac{\partial^2 P[T_1\leq t_1,T_2 \leq t_2 \mid N(t)=2] }{\partial t_1 \partial t_2}\\
&= \frac{2!}{t^2}\frac{\partial^2 t_1(t_2-t_1)}{\partial t_1 \partial t_2}\\
&=\frac{2!}{t^2}\frac{\partial t_1}{\partial t_1}\\
&= \frac{2!}{t^2}
\end{align*}
Veamos cuál es la distribución de los estadísticos ordenados para la uniforme $[0,t]$. 

El caso general se sigue análogamente.
\end{proof}

\begin{defi}
Seab $T_1,T_2,\dotsc$ una sucesión de v.a. i.i.d  a una exponencia de parámetro $\lambda$. El proceso de Poisson de parámetro $\lambda$ es el proceso en tiempo continuo $\{N_t:t\geq 0\}$ definido como 
$$
N_t = \max\{n\geq 1\mid T_1+\dotsc T_n \leq t\}
$$
\end{defi}
\begin{defi}
Un proceso de Poisson de parámetro $\lambda > 0$ es un proceso a tiempo continuo $\{N_t \mid t\geq0\}$ con espacio de estados $\{0,1,2\dotsc\}$ con trayectorias no decrecientes y que cumple las siguientes propiedades
\begin{enumerate}
\item $N(0)=0$.
\item Tiene ncrementos independientes
\item $N(t+s)-N(s) \sim Poi(\lambda t)$ $\forall s\geq 0, t>0$.
\end{enumerate}
\end{defi}
\begin{example}
Dos líneas de tren $A$ y $B$ comparten estación. Los trenes de tipo $A$ y$B$ llegan a la estación según procesos de Poisson independientes con tasas $\lambda_A =3$, $\lambda_B =6$ trenes por hora. Supongemos que los viajeros suben y bajan de los trenes instantáneamente.
\begin{itemize}
\item En un instante al azar un pasajero llega a la estación a tomar el tren tipo $A$, ¿cuál es la función de densidad del tiempo que debe esperar para tomar su tren?
$$
f(t) = \lambda_A e^{-t\lambda_A} = 3e^{-3t}
$$
\item ¿Cuál es la probabilidad de que por la estación pasen exactamente $9$ trenes en una hora?
$$
P[N(1)_A + N(1)_B = 9] = P[N(1)_{A+B} = 9] = (\lambda_A + \lambda_B)^9\frac{e^{-(\lambda_A+\lambda_B)}}{9!} = 9^9\frac{e^{-9}}{9!} \approx 0.13175
$$
\item Si un observador cuenta el número de trenes que pasan por la estación cada hora, comenzando a las 8:00 de la mañana, ¿cuál es el número esperado de horas transcurridas hasta que cuenta $9$ trenes?

Si $T_i$ es el tiempo entre el suceso $i$ y el $i+1$, estos son i.i.d a exponenciales de parámetro $A+B=9$, luego
$$
E[T_1 + \dotsc + T_9] = 9 E[T_i] = 1
$$
\end{itemize}
\end{example}
\newpage
\section{Definiciones alternativas}
\begin{defi}
	Un \textit{Proceso de Poisson no homogéneo en el tiempo} es un proceso a tiempo continuo  $\{ X_{t} : t \geq 0 \}$ con espacio de estados $\{ 0,1, \ \dotsc \}$, con parámetro la función positiva e integrable $\lambda(t)$ y que cumple
	\begin{enumerate}
	\item	$X(0)=0$
	\item Tiene incrementos independientes
	
	\item Para todo $t \geq 0$ 
\begin{align*}
P(X_{t+h} - X_{t} =0) &= 1-\lambda(t)h+o(h)\\
P(X_{t+h} - X_{t} =1) &= \lambda(t)h + o(h)\\
P(X_{t+h} - X_{t} \geq 2) &= o(h)
\end{align*}
	\end{enumerate}
\end{defi}

\begin{prop}
	
	La variable $X_{t}$ es un proceso de Poisson no homogéneo de parámetro $\lambda(t)$ tiene una distribución de parámetro $\Lambda(t)$, donde
	$$ \Lambda(t) = \int_{0}^{t} \lambda(s) ds$$	
\end{prop}

\begin{dem}
		Sea $p_{n}(t) = P(X_{t} = n ) $ y sea $h>0$. Denotemos por $p_{n} (t,t+h] =P(X_{t+h}-X_{t}=n)$. Por independencia para $ t \geq 0$ y $h$ decreciente a 0
\begin{align*}
p_{0}(t+h)&= p_{0}(t) p_{0}(t,t+h]\\
& = p_{0}(t)[1- \lambda(t)h +o(h)]\\
p_0(t+h)-p_0(t) &= -\lambda(t)h + o(h)
\end{align*}
Si dividimos por $h$ y hacemos $h\to 0$, se obtiene que $p_{0}'(t) = -\lambda(t)p_{0}(t)$, cuya solución es $p_{0}(t)=e^{-\Lambda(t)}$ con la condición inicial de que $p_0(0)=1$. Calculemos ahora $p_{n}(t)$ para $n \geq 1$. Por independencia, para $t \geq 0$
\begin{align*}
p_n(t+h)&=P[X_{t+h}=n]\\
&=\sum_{i=0}^n p_i(t)p_{n-i}(t,t+h]\\
&= p_n(t)p_0(t,t+h] + p_{n-1}(t)p_1(t,t+h]+o(h)\\
&= p_{n}(t) [1- \lambda(t)h +o(h)] + p_{n-1}(t)[\lambda(t)h+o(h)] \\
p_n(t+h) - p_n(t) &= p_n(t)[-\lambda(t)h+o(h)]+p_{n-1}(t)[\lambda(t)h+o(h)]\\
p_n'(t)&=\lambda(t)(p_n(t)+p_{n-1}(t))
\end{align*}
Ahora bien, manipulando algebraicamente la ecuación anterior, podemos escribir
$$
\frac{d}{dt}\left(e^{\Lambda(t)}p_n(t)\right) = \lambda(t)e^{\Lambda(t)}p_{n-1}(t)
$$
A continuación vamos a probar el resultado por inducción. Para $n=0$ lo hemos visto antes. Nuestra hipótesis de inducción es que
$$
p_n(t)=e^{-\Lambda(t)}\frac{\Lambda(t)^n}{n!}
$$
Por tanto
\begin{align*}
\frac{d}{dt}\left(e^{\Lambda(t)}p_{n+1}(t)\right) &= \lambda(t)e^{\Lambda(t)}p_{n}(t)\\
&= \lambda(t)e^{\Lambda(t)}e^{-\Lambda(t)}\frac{\Lambda(t)^n}{n!}\\
&=\lambda(t)\frac{\Lambda(t)^n}{n!}\\
e^{\Lambda(t)}p_{n+1}(t) &= \frac{\Lambda(t)^{n+1}}{(n+1)!}
\end{align*}
\end{dem}

\begin{prop}
	Para un proceso de Poisson no homogéneo, la variable incremento $X_{t+s}-X_{s}$ tiene una distribución de Poisson de parámetro $$\Lambda(t+s)-\Lambda(s)$$
\end{prop}
\begin{nota}
\begin{itemize}
\item[]
\item Si $\lambda(t)= \lambda$ entonces $\Lambda(t)= \lambda \cdot t$ y estaríamos en el caso homogéneo.
\item Si $\Lambda(t)$ es continua, entonces es derivable y $\Lambda'(t)=\lambda(t)$ y a la función $\Lambda(t)$ se le llama \textit{función de intensidad}.
\item Si $\Lambda(t)$ es un proceso estocástico entonces se dice que el proceso de Poisson no homogéneo es de \textit{Cox}.
\item Se define
	$$ \Lambda^{-1}(t) = inf \{ u \geq 0: \Lambda(u) \geq t \}$$ 
\end{itemize}
\end{nota}
\begin{prop}
	Sea un proceso de Poisson no homogéneo $\{X_{t} \}$ de parámetro $\lambda(t)$. Entonces el proceso $\{X_{\Lambda^{-1}}\}_{ t \geq 0}$  es un proceso de Poisson homogéneo de parámetro $1$ si $\Lambda(t)$ es estrictamente creciente.
\end{prop}



\begin{defi}
	Sea $\{ N(t) : t \geq 0 \}$ un proceso de Poisson y sea $\{ Y_{n} \}_{n \in \mathbb{N}}$ una sucesión de v.a. i.i.d e independientes del proceso de Poisson. Sea $Y_{0} = 0$, el \textit{Proceso de Poisson compuesto} se define como
	
	$$ X_{t} = \sum_{n=0}^{N(t)} Y_{n}$$
	
\end{defi}

\newpage
\begin{prop}
	El proceso de Poisson compuesto cumple las siguientes propiedades:
	\begin{enumerate}
		\item Tiene incrementos independientes y estacionarios.
		
		\item $E(X_{t}) = \lambda t E(Y)$
		
		\item $Var(X_{t}) = \lambda t E(Y^{2})$
		
		\item $cov(X_t, X_s) = \lambda E(Y^{2}) min\{s,t\}$
		
		\item $m_{X_{t}} (u) = exp[\lambda (t) (M_{Y} (u) -1)]$
	\end{enumerate}
\end{prop}

\begin{dem}
Veamos las demostraciones.
\begin{enumerate}
\item Para probar los incrementos independientes sabemos que basta considerar el caso $t_1<t_2\leq t_3 <t_4$. Tenemos que
$$
X_{t_2}-X_{t_1} = \sum_{i=N(t_1)+1}^{N(t_2)} Y_i \qquad X_{t_4}-X_{t_3} = \sum_{i=N(t_3)+1}^{N(t_4)} Y_i
$$
El número de sumandos se distribuye según $N(t_2)-N(t_1) \sim N(t_2-t_1)$ y $N(t_4)-N(t_3)$. La propiedad de incrementos independientes del proceso de Poisson asegura que estas variables son independientes. Dado que las variables $Y_i$ son independientes entre sí, se tiene el resultado.
\item Aplicando la Ley de la Probabilidad total
\begin{align*}
E[X_t] &= E_{N_t}\left[E\left[ X_t \mid N_t = n\right]\right] \\
&=E_{N_t}\left[E\left[\sum_{i=0}^{N_t} Y_i \mid N_t = n\right]\right]\\
&=E[N_T]E[Y]\\
&=\lambda tE[Y]
\end{align*}		
\item Utilizamos la Ley de la Varianza Total
\begin{align*}
Var(X_t) &= E[Var(X_t\mid N_t)]+V(E[X_t\mid N_t)]\\
&=E[N(t)Var(Y)]+Var(N(t)E[Y])\\
&=\lambda t Var(Y)+ E[Y]^2 \lambda t\\
&=\lambda t E[Y^2]
\end{align*}
\item Sea $m=\min\{s,t\}$.
\begin{align*}
cov(X_t,X_s)&=cov\left(\sum_{i=0}^{N(t)} Y_i,\sum_{i=0}^{N(s)} Y_i\right)\\
&= Var\left(\sum_{i=1}^{N(m)} Y_i\right)\\
&=\lambda m E[Y^2] 
\end{align*}
\item La función generatriz de momentos
\begin{align*}
E[e^{sX_t}] &=\sum_i e^{si}P[X_t = i]\\
&=\sum_i e^{si}\sum_{n=0}^\infty P[X_t = i\mid N_t =n ] P[N_t = n]\\
&=\sum_{n=0} P[N_t=n]\sum_i  e^{si} P[Y_1+ \dotsc Y_n = i ]\\
&=\sum_{n=0} P[N_t=n] M_Y(s)^n\\
&= \sum_{n=0} P[N_t=n]e^{n\log(M_Y(s))} \\
&= M_{N_t}(\log(M_Y(s)))\\
&=e^{\lambda(M_Y(s)-1)}
\end{align*}

\end{enumerate}
\end{dem}


\section{Algunos Procesos de Poisson Generalizados}
\end{document}
