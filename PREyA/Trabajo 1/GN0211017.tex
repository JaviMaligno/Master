\documentclass[a4paper,12pt]{article}
\usepackage{makeidx}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amscd,amsthm}
\usepackage{amssymb}
\usepackage{tabularx}
\usepackage{amssymb,eucal,bezier,graphicx}
\usepackage{times,amssymb}
\usepackage[ansinew]{inputenc}
\usepackage{multicol}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage{verbatim}
\usepackage{tikz-cd}
\usepackage{listings}

\newtheorem{thm}{Teorema}[section]
\newtheorem{cor}[thm]{Collorary}
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposición}
\newtheorem{prob}[thm]{Problema}
\newtheorem{defi}[thm]{Definición}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{nota}[thm]{Nota}
\newtheorem{ejem}[thm]{Ejemplo}

\newtheorem{demo}[thm]{Demostración}
\providecommand{\gabs}[1]{\left|{#1}\right|}
\providecommand{\R}{\mathbb{R}}
\begin{document}

\renewcommand\refname{Bibliografía}

%%Los tres siguientes comandos estaban inicialmente desinsertados, pero no funcionaban en concordancia en el texto

\renewcommand{\figurename}{Figure}

\renewcommand\thefigure{\arabic{section}.\arabic{figure}}

\numberwithin{figure}{section}
%\renewcommand{\thebibliography}{References}

%\addto\captionsspanish{%
%\def\bibname{References}%
%}


\begin{center} {\large \bf Cadenas de Markov y Álgebras de Evolución}
\end{center}


\begin{center}
{\bf Rafael González-López}
\end{center}

\begin{center}{
\small Universidad de Sevilla. \\
\small rafaelbenzal96@gmail.com}
\end{center}

\vspace{0.4cm}



\section{Introducción}

Con el fin de realizar un trabajo teórico original para la asignatura de Procesos Estocásticos y Aplicaciones, convengo a estudiar las relaciones existentes entre estas álgebras y las cadenas de Markov. Comenzaremos ofreciendo algunos conceptos preliminares.


\subsection{Preliminares sobre álgebras de evolución}

Partimos de un álgebra $E$ definida sobre un cuerpo $K$, dotada de una operación multiplicativa; si notamos por $\{e_i, i \in \Lambda \}$ una base del álgebra, podemos escribir $e_i \cdot e_j = \displaystyle \sum_{k \in \Lambda} a^k_{ij} \, e_k,$ para algunos $a^k_{ij}\in K,$ donde sólo una cantidad finita de {\em constantes de estructura} $a^k_{ij}$ son distintas de cero para unos valores de $i, j \in \Lambda$ fijados. 
\begin{defi}
Un {\em álgebra de evolución} como aquélla que satisface $a^k_{ij} = 0$ siempre que $i \neq j.$
\end{defi}
Llegados a este punto, renombrando las constantes de estructura, puede escribirse:
$e_i  \cdot e_i = \displaystyle \sum_{j = 1}^v a_{ji} \, e_j$. Así, un álgebra de evolución es aquélla en la que las relaciones entre sus gene\-radores vienen dadas por:

$$
\left\{
\begin{array}{l}
e_i  \cdot e_j = 0, \quad \forall i \neq j \\
e_i  \cdot e_i = \displaystyle \sum_{j = 1}^v a_{ji} \, e_j.
\end{array}
\right.
$$
Veamos a continuación algunas propiedades relativas a esta definición.
\begin{prop}
\begin{enumerate}
\item[]
\item Las álgebras de evolución son conmutativas y flexibles.
\item Las álgebras de evolución, en general, no son asociativas.
\item La suma directa de álgebras de evolución es un álgebra de evolución.
\item El producto de Kronecker de un álgebra de evolución es un álgebra de evolución.
\end{enumerate}
\end{prop}
Existen dos tipos de álgebra de evolución que son consideradas {\em triviales}:
\begin{itemize}
\item Las álgebras de evolución de {\em tipo cero}, que se definen por las relaciones dadas por $e_i  \cdot e_j = 0$ para $i \neq j$ y $e_i^2 = e_i e_i = 0, \forall i, j \in \Lambda$ (es decir, todos los productos entre generadores son nulos).

\item Las álgebras de evolución de {\em tipo no-cero}, que son aquéllas que vienen definidas por $e_i  \cdot e_j = 0$ para $i \neq j$ y $e_i^2 = k \, e_i, \forall i, j \in \Lambda$.
\end{itemize}

Pasamos ahora a introducir el concepto de operador de evolución:

\begin{defi}
Sea $E$ un álgebra de evolución con un conjunto generador $\{e_i \mid i \in \Lambda \}$. Se define el {\em operador de evolución} de $E$ como la aplicación lineal $L$ que lleva cada generador en su cuadrado, es decir:

$$L: E \mapsto E$$ $$L(e_i) = e^2_i = \displaystyle \sum_k a_{ki} e_k, \quad \forall i \in \Lambda.
$$
\end{defi}

\subsection{Preliminares sobre cadenas de Markov}

\begin{defi}
Un {\em proceso estocástico} se define como una familia de variables aleatorias $\{X(t), t\in T\}$. El parámetro $t$ generalmente representa tiempo. $T$ se denomina el {\em conjunto de índices} y es un subconjunto de $(-\infty,+\infty)$. Los valores que toman las variables aleatorias $X(t)$ se denominan {\em estados} y el conjunto de todos los posibles estados forman el {\em espacio de estados del proceso} y este puede ser discreto o continuo.
\end{defi}

\begin{itemize}
\item Si el conjunto de índices es discreto, entonces tenemos un {\em proceso estocástico de parámetro (tiempo) discreto}. En otro caso, si $T$ es continuo, diremos que el proceso es un {\em proceso estocástico de parámetro (tiempo) continuo}.
\item  Del mismo modo que el conjunto de índices puede ser discreto o continuo, el espacio de estados también puede ser discreto o continuo. En caso de ser discreto, el proceso es denominado {\em cadena}. 
\end{itemize}
\begin{defi}
Una {\em cadena de Markov} de tiempo discreto $X=\{X_n, n=0,1,2...\}$ es un proceso estocástico que verifica la propiedad Markoviana:
$$Pr[X_n=s_n\mid X_0=s_0, X_1=s_1,..., X_{n-1}=s_{n-1}]=$$
$$=Pr[X_n=s_n\mid X_{n-1}=s_{n-1}]$$
para todo $n\geq1$ y todo $s_i\in S$, donde $S=\{s_i\mid i\in \Lambda\}$ es un conjunto finito o infinito numerable de estados.
\end{defi}\begin{defi}
Se dice que una cadena de Markov es {\em homogénea} si:
$$Pr[X_n=s_n\mid X_{n-1}=s_{n-1}]=$$
$$=Pr[X_{n+k}=s_n\mid X_{n+k-1}=s_{n-1}]$$
para $k=-(n-1),(n-2),...,-1,0,1,2,...$. Esto es, las probabilidades de transición $p_{ij}(n)=Pr[X_{n+1}=s_j\mid X_n=s_i]$ son independientes de $n$ y pueden escribirse:
$$p_{ij}=Pr[X_{n+1}=s_j\mid X_n=s_i]$$
\end{defi}
\begin{defi}
La {\em matriz de probabilidades de transición} de una cadena de Markov homogénea es:

$$P=
\left(
\begin{array}{ccccc}
p_{11}& p_{12} & \ldots & p_{1j} & \ldots\\
p_{21} & p_{22} & \ldots & p_{2j} & \ldots\\
\vdots & \vdots & \vdots & \vdots & \vdots\\
p_{i1} & p_{i2} & \ldots & p_{ij}& \ldots\\
\vdots & \vdots & \vdots & \vdots & \vdots
\end{array}
\right)$$
\end{defi}
\begin{prop}
Denotamos $p_{ij}^{(m)}=Pr[X_{n+m}=s_j\mid X_n=s_i]$, es decir, la probabilidad de que la cadena de Markov vuelva al estado $s_j$, $m$ instantes de tiempo despu\'es de dejar el estado $s_i$. En notación matricial, se verifican las ecuaciones de Chapman-Kolmogorov:
$$P^{(m)}=P^{(l)}P^{(m-l)}$$
donde, por definición, $P^{(0)}=I$, la matriz identidad.
\end{prop}
\begin{defi}
Se define la probabilidad de que después de dejar el estado $s_j$, la primera vez que vuelve al estado $s_j$ ocurre $n$ instantes más tarde. Se denota esta cantidad por $f_{jj}^{(n)}$, la cual aplicando el Teorema de la Probabilidad Total y usando que $p_{jj}^{(0)}=1$, puede calcularse de forma recursiva como:
$$f_{jj}^{(n)}=p_{jj}^{(n)}-\sum_{l=1}^{n-1}f_{jj}^{(l)} p_{jj}^{(n-l)}, \quad n\geq 1$$

\vspace{0.15cm}

As\'i que, la probabilidad de volver alguna vez al estado $s_j$, denotada por $f_{jj}$, viene dada por:
$$f_{jj}=\sum_{n=1}^{\infty} f_{jj}^{(n)}$$
\end{defi}
\begin{defi}
En una cadena de Markov homogénea de tiempo discreto los estados individuales se clasifican en {\em recurrentes} y {\em transitorios}.

\begin{itemize}
\item Se dice que el estado $s_j$ es {\em recurrente} si $f_{jj}=1$. En este caso, se define el {\em tiempo medio de recurrencia $M_{jj}$ del estado $s_j$} como:
    $$M_{jj}= \sum_{n=1}^{\infty} n f_{jj}^{(n)}$$
    Es el número medio de pasos que se han necesitado para volver al estado $s_j$ por primera vez después de haberlo dejado. Un estado recurrente $s_j$ para el cual $M_{jj}$ es finito se dice que es un estado {\em recurrente positivo} o {\em recurrente no nulo}. Si $M_{jj}=\infty$, se dice que el estado $s_j$ es un estado {\em recurrente nulo}.

\item Se dice que el estado $s_j$ es {\em transitorio} si $f_{jj}<1$.
\end{itemize}
\end{defi}
\begin{thm}
En una cadena de Markov finita, se verifica:
\begin{itemize}
\item Ningún estado es recurrente nulo.
\item Al menos un estado debe ser recurrente positivo, es decir, no todos los estados pueden ser transitorios.
\end{itemize}
\end{thm}

\begin{defi}

El {\em período} de un estado $s_j$ se define como el máximo común divisor del conjunto de enteros $n$ para los cuales $p_{jj}^{(n)}>0$. Un estado cuyo período es $d=1$ se dice que es {\em aperiódico}.
\end{defi}
\begin{defi}
Un estado que es recurrente positivo y aperiódico se dice que es {\em ergódico}. Si todos los estados de una cadena de Markov son ergódicos, entonces la cadena de Markov se denomina {\em ergódica}.
\end{defi}\begin{defi}
Cualquier subconjunto no vacío $S_1$ de $S$ se dice que es {\em cerrado} si ningún estado de $S_1$ conduce a algún estado fuera de $S_1$, es decir:
$$p_{ij}^{(n)}=0, \text{ para } s_i\in S_1,s_j \notin S_1, n\geq 1$$
Si un subconjunto cerrado $S_1$ consta de un único estado, entonces ese estado es un estado {\em absorbente}.
\end{defi}
\begin{defi}
El estado $s_j$ se dice que es {\em alcanzable} o {\em accesible} desde el estado $s_i$ si existe un camino desde el estado $s_i$ al estado $s_j$ con probabilidad no nula, es decir, existe un entero $n$ para el cual $p_{ij}^{(n)}>0$.
\end{defi}

\begin{defi}
Una cadena de Markov se dice {\em irreducible} si cada estado es alcanzable desde cualquier otro estado. En otras palabras, si el conjunto de todos los estados es cerrado y no contiene ningún subconjunto propio que sea cerrado.

\vspace{0.15cm}

Análogamente, se dice que un {\em subconjunto irreducible} es aquel subconjunto cerrado de estados que no contiene subconjuntos propios que sean cerrados. De esta forma, cualquier subconjunto propio de un subconjunto irreducible constituye un conjunto de estados abierto.
\end{defi}

\begin{defi}

Si el estado $s_j$ es alcanzable desde el estado $s_i$ y el estado $s_i$ es alcanzable desde el estado $s_j$, entonces los estados $s_i$ y $s_j$ se dice que son {\em estados comunicados}. 

Un estado que se comunica consigo mismo se denomina {\em estado de vuelta}. Un {\em estado de no vuelta} es aquel que no se comunica consigo mismo. El conjunto de todos los estados que se comunican con el estado $s_i$ forman una {\em clase} y se denota por $C(s_i)$.
\end{defi}

\begin{thm}
Una cadena de Markov en la que todos los estados pertenecen a la misma clase de comunicación  es irreducible.
\end{thm}

\begin{thm}
Una cadena de Markov de tiempo discreto irreducible es recurrente positiva o recurrente nula o transitoria; es decir, o todos los estados son recurrentes positivos, o recurrentes nulos, o transitorios.

Además, todos los estados son periódicos con el mismo período $p$, o si no todos los estados son aperiódicos.
\end{thm}

\begin{thm}
En una cadena de Markov irreducible finita, todos los estados son recurrentes positivos.
\end{thm}

\begin{thm}
Los estados de una cadena de Markov irreducible, finita y aperiódica son ergódicos.
\end{thm}

\newpage
\section{Estados y Clasificación}

\begin{defi}
Sea $X$ una cadena de Markov homogénea con el conjunto de estados $\{e_i\mid i \in \Lambda\}$ y las
probabilidades de transición $p_{ij}=Pr[X_n=e_j\mid X_{n-1}=e_i]$; se define el {\em álgebra de
 evolución $M_X$ correspondiente a $X$} la que tiene a $\{e_i\mid i \in \Lambda\}$ como el conjunto generador y a las siguientes expresiones:

$$R=
\left\{
\begin{array}{l}
e_i^2 = \displaystyle \sum_{k\in \Lambda} p_{ik}e_k, \\
e_i \cdot e_j = 0, \quad i\neq j,
\end{array}
\right.
\newline
$$
\noindent como conjunto de relaciones del álgebra, donde $0\leq p_{ik}\leq 1$ y $\displaystyle
\sum_{k\in \Lambda} p_{ik}=1$.
\end{defi}

Recíprocamente, podemos definir:

\begin{defi}
Sea $E$ un álgebra de evolución con conjunto generador $\{e_i\mid i \in \Lambda\}$ y ley del álgebra la dada por los productos:

$$R=
\left\{
\begin{array}{l}
e_i^2 = \displaystyle \sum_{k\in \Lambda} a_{ik}e_k, \\
e_i \cdot e_j = 0, \quad i\neq j,
\end{array}
\right.
\newline
$$
\noindent donde $0\leq a_{ik}\leq 1$ y $\sum_{k\in \Lambda} a_{ik}=1$. Al álgebra $E$
se le asocia una cadena de Markov tomando como conjunto de estados el conjunto de generadores del
álgebra, y como probabilidades de transición las constantes de estructura. Diremos que un álgebra
de evolución con estas propiedades es un {\em álgebra de evolución Markoviana}.
\end{defi}


\begin{ejem}
Sea un álgebra de evolución de dimensión 4 que tiene como conjunto generador $\{e_1,e_2,e_3,e_4\}$ y como ley del álgebra la que viene dada por los productos:

$$
\begin{array}{lllllllr}
e_1 \cdot e_1 = & 0.5 \, e_1 & + & 0.2 \, e_2 &   &            & + & 0.3 \, e_4, \\
e_2 \cdot e_2 = & 0.1 \, e_1 &   &            & + & 0.9 \, e_3,&   &             \\
e_3 \cdot e_3 = &            &   &            &   & 0.4 \, e_3 & + & 0.6 \, e_4, \\
e_4 \cdot e_4 = &            &   &0.15 \, e_2 &   &            & + & 0.85\, e_4. \\
\end{array}
$$

Este álgebra de evolución tiene asociada una cadena de Markov ya que se satisfacen las condiciones siguientes:

$$
\begin{array}{lll}
0\leq a_{ik}\leq1, & &\forall k,i=1,2,3,4\\
\displaystyle \sum_{k=1}^4 a_{ik}=1, & &\forall i=1,2,3,4\\
\end{array}
$$

Por tanto, es un álgebra de evolución Markoviana y la cadena de Markov asociada tiene como conjunto de estados el conjunto $\{e_1,e_2,e_3,e_4\}$, y como matriz de probabilidades de transición:

$$P=\left(
\begin{array}{ccccc}
0.5 & 0.2 & 0 & 0.3\\
0.1 & 0 & 0.9 & 0 \\
0 & 0 & 0.4 & 0.6 \\
 0 & 0.15 & 0 & 0.85
\end{array}
\right)$$
\end{ejem}
\begin{thm}\label{cerrsubalg}
Sea $C$ un subconjunto del conjunto de estados $S=\{e_i\mid i\in \Lambda\}$ de una cadena de Markov $X$. $C$ es cerrado en el sentido de probabilidad si y sólo si $C$ genera una subálgebra de evolución del álgebra de evolución $M_X$.
\end{thm}


\begin{thm}
Sea $C$ un subconjunto del conjunto de generadores $\{e_i| i\in \Lambda\}$ de un álgebra de
evolución  Markoviana, $C$ genera una subálgebra de evolución del álgebra de evolución Markoviana
si y sólo si:
$$n_{ij}=0, \text{ para } e_i \in C, e_j \notin C, n\geq1$$
donde, según se vio, $n_{ij}$ representa los elementos del operador $L^n$.
\end{thm}

\begin{defi}
Denotamos $\rho_j^0=\sum_{k\neq j} \rho_k$, donde $\rho_j$ nos da la componente de $e_j$, es decir,
si  $x=\sum_{k}a_k e_k$, $\rho_j(x)=a_je_j$. A $\rho_j^0$ se le llama el {\em operador de borrado},
que elimina la componente de $e_j$, esto es, $\rho_j^0(x)=x-\rho_j(x)$. 
\end{defi}
Entonces, se pueden definir
ope\-radores de la primera visita a un generador $e_j$, entendiéndose por primera visita a un
generador la primera vez que se pasa por ese generador. Estos operadores se definen
recurrentemente:
\begin{eqnarray*}
V_j^{(1)} &=& \rho_jL, \\ %\text{ la primera visita sucede en el primer instante,} \\
V_j^{(m)} &=& V_j^{(m-1)}\rho_j^0L, m>1\\  %\text{ la primera visita sucede en el segundo instante,} \\
%V^{(2)} &=& V^{(2)}\rho_j^0L, \text{ la primera visita sucede en el tercer instante,} \\
%& & \ldots \\
%V^{(m)} &=& V^{(m-1)}\rho_j^0L, \text{ la primera visita sucede en el instante m-ésimo.}
\end{eqnarray*}
\begin{defi}
Definimos los operadores destino de la siguiente manera
\begin{eqnarray*}
D_j^n=\displaystyle \sum_{m=1}^{n} \rho_jL(\rho_j^0L)^{(m-1)}\\
D_{j}=\displaystyle \sum_{m=1}^{\infty} \rho_jL(\rho_j^0L)^{(m-1)}\\
\end{eqnarray*}
\end{defi}
De esta forma, $\rho_jL(e_i)$ es el número de caminos simples de longitud $1$  del $e_i$ a $e_j$, donde por camino simple de $e_i$ a $e_j$ se entiende una secuencia de generadores en la que $e_i$ y $e_j$ sólo aparecen al comienzo y al final de esta secuencia, respectivamente, y no se repiten aristas. Análogamente, $\rho_j L(\rho^0_j L)(e_i)$ es el número de caminos simples de longitud 2 del generador $e_i$ al generador $e_j$; $\rho_j L(\rho^0_j L)^2(e_i)$ es el número de caminos simples de longitud 3 del generador $e_i$ al generador $e_j$; etc.

\vspace{0.15cm}

Para cada generador $e_j$, $D_j^n(e_i)=\displaystyle \sum_{m=1}^{n} \rho_jL(\rho_j^0L)^{(m-1)}(e_i)$ nos da el número total de caminos simples de longitudes menores e iguales que $n$ del generador $e_i$ al generador $e_j$.


\begin{thm}
Si $D_j(e_j)=e_j$, entonces el generador $e_j$ es recurrente en el sentido de probabilidad.

Si $D_j(e_j)=ke_j, \quad 0\leq k < 1$, entonces el generador $e_j$ es transitorio  en el sentido de
probabilidad.
\end{thm}

Introducimos un nuevo concepto, similar al ya comentado en los Preliminares sobre cadenas de Markov, aunque ahora en el lenguaje de las álgebras:

\begin{defi}
Dado un generador $e_j$,  el {\em tiempo medio de recurrencia} $H_j$ es el coeficiente  de:

$$H_j=\displaystyle \sum_{n=1}^{\infty} nD_{j,n}$$

Esto es, el número medio de pasos que se han necesitado para llegar al generador $e_j$ por primera
vez. Un generador recurrente $e_j$ para el cual $H_j(e_j)$ es finito se dice que es un generador
{\em recurrente positivo}. En otro caso se dice que el generador $e_j$ es un generador {\em
recurrente nulo}.
\end{defi}


Una vez clasificados los generadores del álgebra de evolución, sabemos que en una cadena de Markov finita, al menos un estado debe ser recurrente positivo, es decir, no todos los estados pueden ser transitorios, por el Teorema 2.3.1. Luego, podemos deducir el siguiente teorema:

\begin{thm}
En un álgebra de evolución finita no todos los generadores pueden ser transitorios, al menos un generador debe ser recurrente.
\end{thm}
\newpage
\section{Periodicidad}
Ahora pasamos a introducir el concepto de período del generador $e_i$ del álgebra de evolución $M_X$ del mismo modo que se define el período de un estado $e_i$ de una cadena de Markov $X$:

\begin{defi}
El {\em período} de un generador $e_j$ se define como el máximo común divisor del conjunto de enteros $n$ para los cuales $n_{jj}> 0$, donde $n_{jj}$ es el elemento de la columna $j$ y fila $j$ de la matriz de representación del operador $L^n$. Un generador con período 1 se dice {\em aperiódico}.
\end{defi}

\begin{ejem}\label{periodo1}
Sea $M_X$ un álgebra de evolución Markoviana que tiene como conjunto generador $\{e_1,e_2,e_3,e_4\}$ y como ley del álgebra la que viene dada por:
$$
\begin{array}{llll}
e^2_1 = & 0.5 \, e_2 & + & 0.5 \, e_3, \\
e^2_2 = & 0.4 \, e_1 & + & 0.6 \, e_2, \\
e^2_3 = & \quad \, e_4, &\\
e^2_4 = & 0.9 \, e_3 & + & 0.1 \, e_4. \\
\end{array}
 $$

Hallamos el período de cada uno de los generadores:

\begin{itemize}
\item
Para el período del generador $e_1$ hallamos el máximo común divisor de 2 y 3, que es 1, ya que los caminos simples que van de $e_1$ en $e_1$ son de longitudes 2 y 3, que corresponden a los caminos simples $e_1,e_2,e_1$ y $e_1,e_2,e_2,e_1$, respectivamente.

\item
El período de $e_2$ es m.c.d$\{1,2\}=1$. Las longitudes 1 y 2 corresponden a los caminos simples $e_2,e_2$ y $e_2,e_1,e_2$.

\item
El período de $e_3$ es m.c.d$\{2,3\}=1$. Las longitudes 2 y 3 corresponden a los caminos simples $e_3,e_4,e_3$ y $e_3,e_4,e_4,e_3$.

\item
El período de $e_4$ es m.c.d$\{1,2\}=1$. Las longitudes 1 y 2 corresponden a los caminos simples $e_4,e_4$ y $e_4,e_3,e_4$.
\end{itemize}
\end{ejem}


Obsérvese que en ambos ejemplos todos los generadores tienen el mismo período. Esto se debe a que una cadena de Markov irreducible es recurrente positiva o recurrente nula o transitoria; es decir, o todos los estados son recurrentes positivos, o todos los estados son recurrentes nulos, o todos los estados
son transitorios. Además, todos los estados son periódicos con el mismo período $p$, o aperiódicos. Así, podemos deducir el teorema siguiente:

\begin{thm}\label{mismoper}
En un álgebra de evolución simple todos los generadores son recurrentes positivos, o en otro caso, todos los generadores son recurrentes nulos, o todos los generadores son transitorios.
Además, todos los generadores son periódicos con el mismo periódo $p$, o sino todos los estados son aperiódicos.
\end{thm}


Hasta aquí hemos discutido la clasificación de los generadores individuales, ahora trataremos las clasificaciones de grupos de generadores.

\begin{prop}
El estado $e_k$ es un estado absorbente en una cadena de Markov $X$ si y sólo si $e_k$ es un elemento idempotente en el álgebra de evolución $M_X$.
\end{prop}

Este resultado es cierto dado que $e_k$ es absorbente en una cadena de Markov $X$ si y sólo si $p_{kk}=1$. De modo que en el álgebra $M_X$, se verifica $e_k \cdot e_k= e_k$.

\section{Aplicación}
Como hemos visto, las cadenas de Markov pueden estudiarse a partir de las álgebras de evolución y recíprocramente. En nuestro caso, vamos a ver cómo podemos utilizar R para estudiar álgebras de evolución a partir de paquetes creados expresamente para el estudio de las cadenas de Markov. Concretamente, usaremos los paquetes \textbf{markovchain} y \textbf{expm}.

Paralelamente a un análisis general de las posibilidades, vamos a analizar un álgebra en particular. Esta será un álgebra de dimensión 4 dada por
\begin{align*}
e_1^2 &= \frac{1}{2}e_1 + \frac{1}{2}e_2 \\
e_2^2 &= \frac{1}{2}e_3 + \frac{1}{2}e_4\\
e_3^2 &= e_2\\
e_4^2 &= \frac{1}{2}e_1 + \frac{1}{2}e_4
\end{align*}
Inicialmente, tenemos que introducir el álgebra de evolución como la matriz estocástica que representa la cadena de Markov que induce, así como un vector con los nombres de los estados.  Los pasamos por método \textbf{new}.
\begin{lstlisting}
new("markovchain",&states=estados,byrow=T,
     transitionMatrix=cmatrix,name="Cadena de Markov")
\end{lstlisting}
Si hacemos \textbf{plot} de este objeto, obtenemos una representación gráfica del grafo que induce el álgebra (o la cadena) con los coeficientes (o probabilidades) como pesos de las aristas.

\begin{figure}
\centering
\includegraphics[scale=0.8]{Captura}
\end{figure}
\newpage
Para clasificar los estados de nuestro álgebra, basta clasificar los estados de la cadena de Markov asociada. Para ello, utilizamos el comando \textbf{summary} en el objeto anterior. Obtenemos la salida
\begin{lstlisting}
## Maquinaria  Markov chain that is composed by: 
## Closed classes: 
## 1 2 3 4 
## Recurrent classes: 
## {1,2,3,4}
## Transient classes: 
## NONE 
## The Markov chain is irreducible 
## The absorbing states are: NONE
\end{lstlisting}

Obtenemos, por tanto, una clasificación completa de los estados. Finalmente, utilizamos el comando \textbf{period} para calcular la periodicidad de los generadores, obteniendo el resultado

\begin{lstlisting}
## [1] 1
\end{lstlisting}

Por lo que todos los estados son aperiódicos.
\newpage

\section{Aplicación}
\begin{thebibliography}{9}
\bibitem{latexcompanion} 
(2008) Evolution Algebras and Markov Chains. In: Evolution Algebras and their Applications. Lecture Notes in Mathematics, vol 1921. Springer, Berlin, Heidelberg

\bibitem{tesistian} Tian, J. P., Evolution algebra theory. Thesis (Ph.D.)University of California, Riverside. 2004. 145 pp. ISBN 978-0496-77534-7.


\bibitem{Petr} Tian, J.P. and Vojtechovsky, P., Mathematical concepts of evolution algebras in non-mendelian genetics,
{\it Quasigroups Related Systems}, {\bf 14}:1 (2006), 111-122.

\end{thebibliography}
\end{document}
