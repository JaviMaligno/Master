\documentclass[PREyA.tex]{subfiles}
\begin{document}

\chapter{Introducción a los procesos estocásticos}
\section{Definiciones}
\begin{defi}
Un \textbf{proceso estocástico} (PE) es un conjunto de variables aleatorias $\{X(t) \mid t  \in T\}$ donde $t$ es un parámetro que pertenece a un conjunto $T$, cuya estructura puede ser cualquiera.
\end{defi}
\begin{nota}
En general, llamaremos al parámetro $t$ \textbf{parámetro temporal}, $T\subset \R$. Cada variable $X_t$ toma valores reales en un conjunto $S\subset \R$ denominado espacio de \textbf{estados}.
\end{nota}
\begin{example}
El número de correos electrónicos en tu bandeja en el instante $t$ o el saldo de tu cuenta bancaria en el instante $t$.
\end{example}

Un proceso estocástico (PE) viene caracterizado por tres propiedades:

\begin{itemize}
\item El espacio de estados, es decir, valores de $X_t$ para cada $t$.
\item El espacio paramétrico, es decir, los valores $t\in T$
\item La relación de dependencia entre las v.a. $X_t$.
\end{itemize}
\begin{defi}
Una primera clasificación que podemos realizar de los PE está determinada por la naturaleza de $T$, es decir, su estructura topológica.
\begin{itemize}
\item Si $T$ es numerable se dice que es un \textbf{proceso discreto}.
\item Si $T$ es no numerable se dice que es un \textbf{proceso continuo}.
\end{itemize}
\end{defi}
\begin{example}
Tomemos como ejemplo el problema de las colas en las cajas de los supermercados. Si queremos predecir el comportamiento de la cola debemos estudiar cuestiones como el comportamiento de la velocidad del servicio o el número de clientes que llegan a la cola.
Un posible enfoque para este problema sería el siguiente:
\begin{itemize}
\item El número de clientes en la cola en el instante $T$ viene dado por $X_t$ para $t\geq 0$ con $X_0 = 0$.
\item El tiempo de llegada entre clientes sucesivos son independientes y sigue una distribución conocida $F$.Normalmente, una distribución exponencial, pero hay que contrastarlo.
\item Los clientes son servidos según orden de llegada.
\item Los tiempos de servicios son independientes entre sí y con las llegadas según una distribución conocida $G$. 
\end{itemize}
\end{example}
\section{Ley de Probabilidad de un PE}
\begin{defi} Sea $\{X_t\}_{t\in T}$ un PE. Fijados unos valores finitos $t_1<\dotsc<t_n$ se tiene la \textbf{función de distribución conjunta} del vector aleatorio $(X_{t_1},\dotsc,X_{t_n})$ como
$$
F_{(X_{t_1},\dotsc,X_{t_n}) }(x_1,\dotsc,x_n): = P[X_{t_1}\leq x_1,\dotsc,X_{t_n}\leq x_n]
$$
para todo $(x_1,\dotsc,x_n) \in \R^n$. También será común usar la notación abreviada
$$
F_{t_1,\dotsc,t_n}(x_1,\dotsc,x_n)
$$
\end{defi}
\begin{nota}
Un PE determina un sistema de distribuciones finito dimensionales.
\end{nota}
\begin{defi}
El conjunto dado por $\{X_t(w)\mid w \in \Omega\}$ para cada $t$ se llama \textbf{trayectoria o camino muestral} del PE.
\end{defi}

\section{Condiciones de consistencia de Kolmogorov}
\begin{defi}
Se definen las \textbf{condiciones de consistencia de Kolmogorov} como sigue:
\begin{itemize}
\item \textbf{Condición de simetría}. La función de distribución conjunta debe ser simétrica en los pares $(t_j,x_j)$. Es decir, sea $\sigma \in S_n$ una permutación de $\{1,\dotsc,n\}$:
$$
F_{t_1,\dotsc,t_n}(x_1,\dotsc,x_n) = F_{t_{\sigma(1)},\dotsc,t_{\sigma(n)}}(x_{\sigma(1)},\dotsc,x_{\sigma(n)})
$$
\item \textbf{Condición de consistencia}.
$$\lim_{x_n \to \infty} F(x_1,\dotsc,x_n) = F(x_1,\dotsc,x_{n-1})
$$

\end{itemize}
\end{defi}
\begin{nota}
Es claro que la familia de distribuciones que determina un PE verifica estas condiciones. Recíprocamente, podríamos preguntarnos si una familia consistente de distribuciones determina un proceso estocástico. La respuesta es sí y está dada por el Teorema de Consistencia de Kolmogorv.
\end{nota}
\begin{defi}
Sea $\{X_t \mid t \in T\}$ un PE con momentos de segundo orden finito ($E[X_t^2] < \infty$, $\forall t \in T$). Definimos la \textbf{función del valor medio}, representada por $m(t)$, como
$$
m(t) = E[X_t]
$$
\end{defi}
\begin{defi}
En las condiciones de la definición anterior definimos la \textbf{función núcleo de covarianza}, representada por $k(s,t)$, como
$$
k(s,t) = Cov(X_s,X_t)\; \forall s,t \in T
$$
\end{defi}
\begin{example}
Supongamos el PE dado por la ley $X_t = X_0 + tV$ donde $X_0$ y $V$ son v.a. y $t\in \R$. Calcular su función media y el núcleo de covarianza
$$
E[X_t] = E[x_0] + tE[V]
$$
$$
k(s,t) =Cov(X_0 + tV, X_0+sV) = Var[X_0] + (s+t)Cov(X_0,V) +ts Var(V)
$$
\end{example}
\section{Propiedades}
\begin{defi}
Se dice que un PE tiene \textbf{incrementos independientes} si $X_0 = 0$ y para cualquier colección finita $0\leq t_1 < \dotsc < t_n$ las variables
$$
X_{t_2}-X_{t_1}, X_{t_3}-X_{t_2}, \dotsc, X_{t_n}-X_{t_{n-1}}
$$
son mutuamente independientes.
\end{defi}
\begin{example}
Sean $\{X_n\}_{n\in \mathbb{N}}$ un conjunto de v.a. i.i.d y consideremos el PE dado por $S_0 = 0$, $S_n = X_1 + \dotsc + X_n$. Vamos a demostrar que esta familia verifica la definición anterior. Sean $0 \leq t_1 \leq \dotsc \leq t_n$ y sean $i<j \in \{1,\dotsc,n\}$, entonces
\begin{align*}
S_{t_i} - S_{t_{i-1}} &= \sum_{k=t_{i-1}+1}^{t_i} X_k\\
S_{t_j} - S_{t_{j-1}}  &= \sum_{k=t_{j-1}+1}^{t_j} X_k
\end{align*}
Como $i <j$, en las dos sumas no está presente ninguna variable de manera simultánea. Dado las $X_i$ son independientes, tenemos que los sumatorios son independientes y así el resultado.
\end{example}

\begin{defi}
Se dice que un PE tiene \textbf{incrementos independiente estacionarios} si tiene incrementos independientes y además variables aletorias $X_{t+h} - X_{s+h}$ y $X_t - X_s$ tienen la misma distribución para todo $h>0$ y $t> s$. 
\end{defi}
\begin{defi}
Se dice que un PE es \textbf{independiente} si cualquier colección de variables aleatorias del PE son independientes.
\end{defi}
\newpage
\begin{defi}
Se dice que un PE es \textbf{markoviano} si verifica la propiedad de Markov, es decir, si verifica
$$
P[X_{t_n} \leq x_n \mid X_{t_1},\dotsc, X_{t_{n-1}}] = P[X_{t_n} \leq x_n \mid X_{t_{n-1}}] \;\forall t_1 < \dotsc < t_n
$$
\end{defi}
\begin{defi}
Un proceso estocástico markoviano con espacio de estados discreto se denomina \textbf{cadena de Markov}.
\end{defi}
\begin{example} Demostrar que el ejemplo anterior es un proceso markoviano. ¿Es una cadena de Markov? Basta usar las propiedades de independencia entre las variables y el hecho de que $S_n = S_{n-1}+X_n$. Que sea o no cadena de Markov depende de la distribución de las variables $X_i$.
\end{example}
\begin{defi}
Un proceso estocástico PE se dice que una \textbf{martingala} si para cualquier colección finita se cumple que 
$$
E[X_{t_n} \mid X_{t_1},\dotsc,X_{t_{n-1}}] = X_{t_{n-1}}
$$
\end{defi}
\begin{defi}
Un proceso estocástico se dice que es \textbf{estacionario u homogéneo} en el tiempo si las distribuciones son invariantes por traslaciones en el tiempo. Es decir
$$
(X_{t_1}, \dotsc, X_{t_n} ) \overset{d}{=} (X_{t_1+h},\dotsc, X_{t_n+h} )
$$
Un PE no estacionario se llama \textbf{evolutivo}.
\end{defi}
\begin{defi}
Un PE se dice que es \textbf{débilmente estacionario} si $\forall t,s \in T$, $\forall h>0$
$$E[X_{t+h}] = E[X_t] \qquad E[X_{t+h}X_{s+h}]  = E[X_tX_s]$$
\end{defi}

\section{Algunos PE comunes}
\begin{defi}
Una sucesión de v.a. $\{X_n\}_{n \in \mathbb{N}}$ se dice qiue es un \textbf{proceso de Bernoulli} con probabilidad de éxito $p$ si las v.a. son independientes y $X_n \sim Be(p)$ para todo $n \in \mathbb{N}$. Se trata de un proceso independiente y por tanto
$$
P[X_{i_1} = r_1,\dotsc,X_{i_k}=r_k] = \prod_{j=1}^k p^{r_j}(1-p)^{1-r_j}
$$
\end{defi}

\begin{defi}
Sea $\{X_n\}_{n \in \mathbb{N}}$ un proceso de Bernoulli con probabilidad de éxito $p$. Al proceso $ S_n = \sum_{i=1}^n X_i$ se le conoce con el nombre de \textbf{proceso binomial}.
\end{defi}

\begin{example}
Calcular la función media, el núcleo de covarianza y las propiedades funtamentales del proceso Binomial.
\begin{align*}
m(s) &= E[X_1 + \dotsc X_s] = \sum_{i=1}^s E[X_i] = sp\\
k(s,t) &= Cov(S_s, S_t) = min(s,t) p(1-p)
\end{align*}
Pasemos a estudiar las propiedades
\begin{itemize}
\item \textbf{Incrementos independientes}. Es consecuencia del Ejemplo 1.4.2. 
\item \textbf{Incrementos estacionarios independientes}. Si $t>s$ entonces  $S_{t+h}-S_{s+h} \sim Bi(t-s,p)$ y $S_{t}-S_{s} \sim Bi(t-s,p)$.
\item \textbf{Independencia}. Claramente no lo es, pues $S_1 = X_1$ no es independiente de $S_2 = X_1+ X_2$.
\item \textbf{Proceso markoviano}. Se deduce trivialmente del hecho de que las $X_i$ sean independientes y que $S_n = S_{n-1}+X_n$.
\item \textbf{Cadena de Markov}. Es cadena de Markov pues el espacio de estados de cada $S_t$ viene dado por la suma finita de variables discretas.
\item \textbf{Martingala}. Se tiene que
$$E[S_2\mid S_1=x_1] = E[X_1+X_2|X_1 = x_1] = E[X_2-x_1] = p+x_1$$
Solo podría ser si $p=0$.
\item \textbf{Estacionario}. Claramente no lo es, pues en particular se estacionario implica que las variables del proceso son idénticamente distribuidas y no es el caso. 
\item \textbf{Débilmente estacionario}. Tampoco lo es, $m(s)$ no es constante.
\end{itemize}
\end{example}

\begin{defi}
Sea $X_n$ una sucesion de v.a. independientes e idénticamente distribuídas. Al proceso $S_n = S_0 + X_1 + \dotsc + X_n$ se le conoce con el nombre de \textbf{Camino Aleatorio sobre la Recta}.
\end{defi}

\begin{example}
Calcular la función media, el núcleo de covarianza y las propiedades funtamentales del proceso camino aleatorio. Sea $\mu = E[X_i]$ y sea $s>t$.
\begin{align*}
m(s) &= E[S_0 +X_1 + \dotsc X_s] = E[S_0] + \sum_{i=1}^s E[X_i] = E[S_0] + s\mu\\
k(s,t) &=  Cov\left(\sum_{i=0}^t X_i + \sum_{i=t+1}^s X_i,\sum_{i=0}^t X_i \right) = Var[S_0] + tVar[X_1]+sCov(S_0,X_1)
\end{align*}
Pasemos a estudiar las propiedades
\begin{itemize}
\item Las propiedades de \textbf{incrementos independientes}, \textbf{incrementos estacionarios independientes}, \textbf{independencia}, \textbf{martingala} \textbf{(débilemente) estacionario} son análogas a las del ejemplo anterior.
\item \textbf{Proceso markoviano}. 
\item \textbf{Cadena de Markov}. Depende de las distribuciones de las variables del proceso.
\end{itemize}
\end{example}
\begin{defi} Supongamos un juego donde se gana una unidad con probabilidad $p$ y pierde una unidad con probabilidad $1-p$. Queremos conocer la probabilidad de ganar $a$ unidades antes de perder $b$. A este juego se le denomina la \textbf{ruina del jugador}.

Definamos $S_n = X_1 + \dotsc + X_n$ con $P[X_i = 1] = p$ y $P[X_i=-1] = 1-p$.

El objetivo es conocer $w_k = P[\text{Ganar $a$ antes de perder $b$ si tenemos $k$})$, entonces $w_a =1$ y $w_b = 0$. 
\end{defi}

\begin{prop}
Mediante independencia y las condicionadas se obtiene que
$$
w_k = pw_{k+1} + qw_{k-1} 
$$
para $b<k<a$. La solución general viene dada por
$$
w_k  = \alpha + \beta \left(\frac{q}{p}\right)^k 
$$
con $p \neq q$ y $\alpha,\beta$ constantes. Con las condiciones iniciales podemos calcular $\alpha$ y $\beta$, teniendo que la solución general es
$$
w_k = \frac{(q/p)^b - (q/p)^k}{(q/p)^b-(q/p)^a}
$$
para $b<k<a$, $p \neq q$.


\end{prop}

\begin{defi}[Tiempo de ocurrencia entre sucesos]
Sea $\{T_j \mid k \in \mathbb{N}\}$ donde $T_k$ es el instante en el que ocurre el $k$-ésimo suceso y sea $N_n$ el numero de éxitos hasta el instante $n$. El PE verifica las propiedades
\begin{itemize}
\item $T_k <= n$ si y sólo si $ N_n >= k$. Si $T_k <= n$ al menos han ocurrido $k$ éxitos en el instante $n$, luego $N_n >= k$. El recíproco es análogo.
\item $T_k = n$ si y solo si $N_{n-1} = k-1$ y $X_n = 1$. También se tiene de manera inmediata.
\end{itemize}
\end{defi}
\begin{example} Calcular la función de densidad y probabilidad de $T_k$. Dado que los sucesos $X_i$ son i.i.d. a una ley $Be(p)$, tenemos que $N_n \sim Bi(n,p)$. Por las equivalencias anteriores podemos escribir
$$
F_k(n) = P[T_k \leq n ] = P[N_n \geq k] = 1 - P[N_n < k] = 1 - P[N_n \leq k -1] = 1- \sum_{i=0}^{k-1}\binom{n}{i}p^iq^{n-i}
$$
$$
P[T_k = n] = P[N_{n-1} =k-1]P[X_n = 1] = \binom{n-1}{k-1}p^kq^{n-k}
$$
\end{example}
\begin{prop}
Las variables aleatorias $T_1, T_2-T_1,\dotsc,T_k-T_{k-1},\dotsc$ son indepentientes y e identicamente distribuidads. Es más, para $m,k\geq 1$ 
$$
P[T_{k+1} - T_k = m] = pq^{m-1}
$$
\end{prop}
\begin{example}
Obtener las propiedes estocásticas de $T_k$. 
\begin{itemize}
\item \textbf{Incrementos independientes}. Basta probarlo para el caso $n=2$. Sean $m_1 < m_2 < m_3$ entonces podemos escribir
$$
T_{m_2}- T_{m_1}  = (T_{m_2}- T_{m_2-1}) + … + (T_{m_{1}+1}- T_{m_1})
$$
y análogamente para $T_{m_3}- T_{m_2}$. Por la proposición anterior, las diferencias se pueden escribir como suma de variables independientes, luego las sumas han de ser independientes.

\item \textbf{Incrementos estacionarios}. Se deduce inmediatamente a partir de la proposición, pues podemos expandir tanto $T_{t+h}-T_{s+h}$ como $X_t - X_s$ en sumas de $t-s$ variables independientes e identicamente distribuidas.

\item \textbf{Independencia}. Claramente no lo son, pues $T_1$ y $T_2$ (p.e) no lo son, ya que $T_1$ y $T_2-T_1$ sí lo son, luego 

$$
Cov(T_1,T_2-T_1) = 0 = Cov(T_1,T_2) - Var(T_1) \Rightarrow Cov(T_1,T_2) = Var(T_1). 
$$

Como $T_1$ no es constante, su varianza no puede ser nula.
\item \textbf{Proceso markoviano}. Para $T_1,T_2,T_3$ la ecuacion implicaria $T_3$ independiente de $T_1$, lo cual no es cierto.

\item \textbf{Cadena de Markov}. Al no ser proceso markoviano tampoco puede ser cadena de Markov.
\item Martingala
\item \textbf{Estacionario}. Claramente no puede serlo, pues en particular las $T_k$ deberían ser idénticamente distribuidas.
\item \textbf{Débilmente estacionario}. Si calculamos explícitamente la esperanza de $T_k$ observamos
$$
E[T_k] = \sum_{n=k}^\infty n \binom{n-1}{k-1}p^k(1-p)^{n-k} = \frac{p}{k}
$$
Como para distintos $\forall k,k'$ con $k\neq k'$ las esperanzas son distintas, no puede ser débilmente estacionario.
\end{itemize}
\end{example}



\end{document}
